{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pod5 as p5\n",
    "import pysam\n",
    "import logging\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "\n",
    "logger = logging.getLogger(\"test_logger\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "test_log = logging.FileHandler(\n",
    "    \"/home/xiaoyf/methylation/deepsignal/log/normalize.log\", \"a\", encoding=\"utf-8\"\n",
    ")\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(filename)s - line:%(lineno)d - %(levelname)s - %(message)s\"\n",
    ")\n",
    "test_log.setFormatter(formatter)\n",
    "# 加载文件到logger对象中\n",
    "logger.addHandler(test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signal_from_pod5(pod5_path) -> np.array:\n",
    "    signals = []\n",
    "    with p5.Reader(pod5_path) as reader:\n",
    "        for read_record in reader.reads():\n",
    "            if read_record.signal is None:\n",
    "                logger.critical(\n",
    "                    \"Signal is None for read id {}\".format(read_record.read_id)\n",
    "                )\n",
    "            # signals[str(read_record.read_id)] = {'signal':read_record.signal,'shift':read_record.calibration.offset,'scale':read_record.calibration.scale}#不加str会变成UUID，很奇怪\n",
    "            signals.append(\n",
    "                [\n",
    "                    str(read_record.read_id),\n",
    "                    read_record.signal.astype(np.int16),\n",
    "                    np.int16(read_record.calibration.offset),\n",
    "                    np.float16(read_record.calibration.scale),\n",
    "                ]\n",
    "            )\n",
    "            # 0:read_id,1:signal,2:shift,3:scale\n",
    "    return np.array(signals, dtype=object)  # np.array is small than list\n",
    "\n",
    "\n",
    "def extract_move_from_bam(bam_path) -> np.array:\n",
    "    seq_move = []\n",
    "    bamfile = pysam.AlignmentFile(bam_path, \"rb\", check_sq=False)\n",
    "    try:\n",
    "        for read in bamfile.fetch(until_eof=True):  # 暂时不使用索引，使用返回是空值\n",
    "            # print(read.query_name)\n",
    "            tags = dict(read.tags)\n",
    "            mv_tag = tags[\"mv\"]\n",
    "            ts_tag = tags[\"ts\"]\n",
    "            sm_tag = tags[\"sm\"]\n",
    "            sd_tag = tags[\"sd\"]\n",
    "            # read.update({read.query_name:{\"sequence\":read.query_sequence,\"stride\":mv_tag[0],\"mv_table\":np.array(mv_tag[1:]),\"num_trimmed\":ts_tag,\"shift\":sm_tag,\"scale\":sd_tag}})\n",
    "            seq_move.append(\n",
    "                [\n",
    "                    read.query_name,\n",
    "                    read.query_sequence,\n",
    "                    np.int16(mv_tag[0]),\n",
    "                    np.array(mv_tag[1:], dtype=np.int16),\n",
    "                    np.int16(ts_tag),\n",
    "                    np.float16(sm_tag),\n",
    "                    np.float16(sd_tag),\n",
    "                ]\n",
    "            )\n",
    "    except ValueError:\n",
    "        print(\"bam don't has index\")\n",
    "        for read in bamfile.fetch(until_eof=True, multiple_iterators=False):\n",
    "            tags = dict(read.tags)\n",
    "            mv_tag = tags[\"mv\"]\n",
    "            ts_tag = tags[\"ts\"]\n",
    "            sm_tag = tags[\"sm\"]\n",
    "            sd_tag = tags[\"sd\"]\n",
    "            seq_move.append(\n",
    "                [\n",
    "                    read.query_name,\n",
    "                    read.query_sequence,\n",
    "                    np.int16(mv_tag[0]),\n",
    "                    np.array(mv_tag[1:], dtype=np.int16),\n",
    "                    np.int16(ts_tag),\n",
    "                    np.float16(sm_tag),\n",
    "                    np.float16(sd_tag),\n",
    "                ]\n",
    "            )\n",
    "            # 0:read_id,1:sequence,2:stride,3:mv_table,4:num_trimmed,5:to_norm_shift,6:to_norm_scale\n",
    "            # read[read.query_name] = {\"sequence\":read.query_sequence,\"stride\":mv_tag[0],\"mv_table\":np.array(mv_tag[1:]),\"num_trimmed\":ts_tag,\"shift\":sm_tag,\"scale\":sd_tag}\n",
    "    return np.array(seq_move, dtype=object)\n",
    "\n",
    "\n",
    "def read_from_pod5_bam(pod5_path, bam_path, read_id=None) -> np.array:\n",
    "    read = []\n",
    "    signal = extract_signal_from_pod5(pod5_path)\n",
    "    seq_move = extract_move_from_bam(bam_path)\n",
    "    if read_id is not None:\n",
    "        for i in range(len(seq_move)):\n",
    "            if seq_move[i][0] == read_id:\n",
    "                if seq_move[i][1] is not None:\n",
    "                    for j in range(len(signal)):\n",
    "                        if signal[j][0] == seq_move[i][0]:\n",
    "                            read.append(\n",
    "                                [\n",
    "                                    signal[j][0],\n",
    "                                    signal[j][1],\n",
    "                                    signal[j][2],\n",
    "                                    signal[j][3],\n",
    "                                    seq_move[i][1],\n",
    "                                    seq_move[i][2],\n",
    "                                    seq_move[i][3],\n",
    "                                    seq_move[i][4],\n",
    "                                    seq_move[i][5],\n",
    "                                    seq_move[i][6],\n",
    "                                ]\n",
    "                            )\n",
    "\n",
    "    else:\n",
    "        for i in range(len(seq_move)):\n",
    "            if seq_move[i][1] is not None:\n",
    "                for j in range(len(signal)):\n",
    "                    if signal[j][0] == seq_move[i][0]:\n",
    "                        read.append(\n",
    "                            [\n",
    "                                signal[j][0],\n",
    "                                signal[j][1],\n",
    "                                signal[j][2],\n",
    "                                signal[j][3],\n",
    "                                seq_move[i][1],\n",
    "                                seq_move[i][2],\n",
    "                                seq_move[i][3],\n",
    "                                seq_move[i][4],\n",
    "                                seq_move[i][5],\n",
    "                                seq_move[i][6],\n",
    "                            ]\n",
    "                        )\n",
    "                # 0:read_id,1:signal,2:to_pA_shift,3:to_pA_scale,4:sequence,5:stride,6:mv_table,7:num_trimmed,8:to_norm_shift,9:to_norm_scale\n",
    "\n",
    "    return np.array(read, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:read_id,1:signal,2:to_pA_shift,3:to_pA_scale,4:sequence,5:stride,6:mv_table,7:num_trimmed,8:to_norm_shift,9:to_norm_scale\n",
    "def norm_signal_read_id(signal) -> np.array:\n",
    "    shift_scale_norm = []\n",
    "    # signal_norm=[]\n",
    "    if signal[3] == 0:\n",
    "        logger.critical(\"to_pA_scale of read {} is 0\").format(signal[0])\n",
    "    shift_scale_norm = [\n",
    "        (signal[8] / signal[3]) - np.float16(signal[2]),\n",
    "        (signal[9] / signal[3]),\n",
    "    ]\n",
    "    # 0:shift,1:scale\n",
    "    num_trimmed = signal[7]\n",
    "    # print('num_trimmed:{} and signal:{}'.format(num_trimmed,signal[1]))\n",
    "    # print('shift:{} and scale:{}'.format(shift_scale_norm[0],shift_scale_norm[1]))\n",
    "    if shift_scale_norm[1] == 0:\n",
    "        logger.critical(\"scale of read {} is 0\").format(signal[0])\n",
    "    if num_trimmed >= 0:\n",
    "        signal_norm = (\n",
    "            signal[1][num_trimmed:].astype(np.float16) - shift_scale_norm[0]\n",
    "        ) / shift_scale_norm[1]\n",
    "    else:\n",
    "        signal_norm = (\n",
    "            signal[1][:num_trimmed].astype(np.float16) - shift_scale_norm[0]\n",
    "        ) / shift_scale_norm[1]\n",
    "\n",
    "    return signal_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for '/homeb/xiaoyf/data/HG002/example/bam/has_moves.bam'\n"
     ]
    }
   ],
   "source": [
    "pod5_path = \"/homeb/xiaoyf/data/HG002/example/pod5/output.pod5\"\n",
    "bam_path = \"/homeb/xiaoyf/data/HG002/example/bam/has_moves.bam\"\n",
    "reads = read_from_pod5_bam(pod5_path, bam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_signals(signals, normalize_method=\"mad\"):\n",
    "    sig = signals.astype(np.float64)\n",
    "    if normalize_method == \"zscore\":\n",
    "        sshift, sscale = np.mean(sig), np.std(sig)\n",
    "    elif normalize_method == \"mad\":\n",
    "        sshift, sscale = np.median(sig), robust.mad(sig)\n",
    "    else:\n",
    "        raise ValueError(\"\")\n",
    "    norm_signals = (sig - sshift) / sscale\n",
    "    return np.around(norm_signals, decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   read id raw max     raw mean raw min  \\\n",
      "0     3239b4d9-0a7e-471c-86fe-e156b9f279a0    1318   899.075692     599   \n",
      "1     732722e8-65c8-4ad1-b4d5-f9ec85e830d3    1466  1007.847152     654   \n",
      "2     77a9f606-58bd-42a9-b7f8-a3bb26d97e7f    1465   936.392630     626   \n",
      "3     7cb07bb1-5ea7-4eb0-a974-fce4e4381a9b    1284   894.430262     583   \n",
      "4     7d5dd8ce-045d-49ac-964d-a13c9d119380    1373   924.243811     593   \n",
      "...                                    ...     ...          ...     ...   \n",
      "3995  fed81f0c-0944-4edf-b39f-d735ef2e68bd    1280   841.526710     480   \n",
      "3996  fedb5e31-1b54-44cc-a0d0-2fa37b810582    1442   952.077405     504   \n",
      "3997  fef04f59-0dad-4460-b3ec-f6dad1e8941f    1583   908.010156     449   \n",
      "3998  fe987708-476a-422c-b4ea-86766b8a2ccf    1256   843.874054     470   \n",
      "3999  fe48f4ae-94c4-4b9a-b0af-2d21b26901f5    1387   914.702922     303   \n",
      "\n",
      "      raw median  linalg.norm max  linalg.norm mean  linalg.norm min  \\\n",
      "0          899.0         0.023801          0.016236         0.010817   \n",
      "1         1032.0         0.014560          0.010010         0.006496   \n",
      "2          976.0         0.017408          0.011127         0.007439   \n",
      "3          928.0         0.024969          0.017394         0.011337   \n",
      "4          961.0         0.014937          0.010055         0.006451   \n",
      "...          ...              ...               ...              ...   \n",
      "3995       876.0         0.004080          0.002682         0.001530   \n",
      "3996       985.0         0.003389          0.002238         0.001184   \n",
      "3997       935.0         0.005421          0.003110         0.001538   \n",
      "3998       880.0         0.002610          0.001754         0.000977   \n",
      "3999       939.0         0.002725          0.001797         0.000595   \n",
      "\n",
      "      linalg.norm median  remora max  ...   mad max  mad mean   mad min  \\\n",
      "0               0.016235    1.980469  ...  2.047546  0.005213 -1.453426   \n",
      "1               0.010250    1.970703  ...  2.032858 -0.113814 -1.770770   \n",
      "2               0.011598    2.785156  ...  3.083015 -0.250553 -2.205579   \n",
      "3               0.018046    2.048828  ...  2.075136 -0.190938 -1.999193   \n",
      "4               0.010455    2.218750  ...  2.295464 -0.205742 -2.051218   \n",
      "...                  ...         ...  ...       ...       ...       ...   \n",
      "3995            0.002792    2.269531  ...  2.272124 -0.193829 -2.225816   \n",
      "3996            0.002315    2.355469  ...  2.407304 -0.173451 -2.533427   \n",
      "3997            0.003202    2.255859  ...  2.372344 -0.157050 -2.776759   \n",
      "3998            0.001829    2.185547  ...  2.266137 -0.217671 -2.470656   \n",
      "3999            0.001845    2.255859  ...  2.305424 -0.125103 -3.274428   \n",
      "\n",
      "      mad median   mad std  raw mad max  raw mad mean  raw mad min  \\\n",
      "0            0.0  0.746975     2.033174      0.000367    -1.455733   \n",
      "1            0.0  0.789258     2.032837     -0.113131    -1.770536   \n",
      "2            0.0  0.957017     3.082481     -0.249671    -2.206275   \n",
      "3            0.0  0.887474     2.069986     -0.195193    -2.006026   \n",
      "4            0.0  0.874472     2.296610     -0.204890    -2.051341   \n",
      "...          ...       ...          ...           ...          ...   \n",
      "3995         0.0  0.836285     2.270782     -0.193766    -2.225816   \n",
      "3996         0.0  0.841585     2.408139     -0.173484    -2.534606   \n",
      "3997         0.0  0.858914     3.703978     -0.154274    -2.777983   \n",
      "3998         0.0  0.875962     2.264358     -0.217559    -2.469114   \n",
      "3999         0.0  0.816089     2.306652     -0.125100    -3.274622   \n",
      "\n",
      "      raw mad median  raw mad std  \n",
      "0                0.0     0.744968  \n",
      "1                0.0     0.789035  \n",
      "2                0.0     0.957147  \n",
      "3                0.0     0.886853  \n",
      "4                0.0     0.874604  \n",
      "...              ...          ...  \n",
      "3995             0.0     0.836144  \n",
      "3996             0.0     0.841861  \n",
      "3997             0.0     0.862841  \n",
      "3998             0.0     0.875653  \n",
      "3999             0.0     0.816189  \n",
      "\n",
      "[4000 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# 0:read_id,1:signal,2:to_pA_shift,3:to_pA_scale,4:sequence,5:stride,6:mv_table,7:num_trimmed,8:to_norm_shift,9:to_norm_scale\n",
    "df = pd.DataFrame(columns=['read id', 'raw max', 'raw mean', 'raw min', 'raw median', \n",
    "                           'linalg.norm max', 'linalg.norm mean', 'linalg.norm min', 'linalg.norm median',\n",
    "                           'remora max', 'remora mean', 'remora min', 'remora median', 'remora std',\n",
    "                           'mad max', 'mad mean', 'mad min', 'mad median', 'mad std',\n",
    "                           'raw mad max', 'raw mad mean', 'raw mad min', 'raw mad median', 'raw mad std'])\n",
    "for read in reads:\n",
    "    logger.info('read id: {}'.format(read[0]))\n",
    "    rmax=np.max(read[1])\n",
    "    rmean=np.mean(read[1])\n",
    "    rmin=np.min(read[1])\n",
    "    rmedian=np.median(read[1])\n",
    "    logger.info('raw max: {}'.format(rmax))\n",
    "    logger.info('raw mean: {}'.format(rmean))\n",
    "    logger.info('raw min: {}'.format(rmin))\n",
    "    logger.info('raw median: {}'.format(rmedian))\n",
    "    if np.any(read[1] + abs(np.min(read[1]))<0):\n",
    "        logger.critical(abs(np.min(read[1])))\n",
    "        logger.critical(read[1])\n",
    "        logger.critical(read[1] + abs(np.min(read[1])))\n",
    "    else:\n",
    "        logger.info('raw bincount: {}'.format(np.argmax(np.bincount(read[1] + abs(np.min(read[1]))))))\n",
    "    norm_sigal=read[1]/np.linalg.norm(read[1])\n",
    "    lmax=np.max(norm_sigal)\n",
    "    lmean=np.mean(norm_sigal)\n",
    "    lmin=np.min(norm_sigal)\n",
    "    lmedian=np.median(norm_sigal)\n",
    "    logger.debug('linalg.norm max: {}'.format(lmax))\n",
    "    logger.debug('linalg.norm mean: {}'.format(lmean))\n",
    "    logger.debug('linalg.norm min: {}'.format(lmin))\n",
    "    logger.debug('linalg.norm median: {}'.format(lmedian))\n",
    "    norm_sigal=norm_signal_read_id(read)\n",
    "    re_max = np.max(norm_sigal)\n",
    "    re_mean = np.mean(norm_sigal)\n",
    "    re_min = np.min(norm_sigal)\n",
    "    re_median = np.median(norm_sigal)\n",
    "    re_std = np.std(norm_sigal.astype(np.float64))#\n",
    "    logger.info('remora max: {}'.format(re_max))\n",
    "    logger.info('remora mean: {}'.format(re_mean))\n",
    "    logger.info('remora min: {}'.format(re_min))\n",
    "    logger.info('remora median: {}'.format(re_median))\n",
    "    logger.info('remora std: {}'.format(re_std))\n",
    "    norm_sigal=_normalize_signals(norm_sigal)\n",
    "    mad_max = np.max(norm_sigal)\n",
    "    mad_mean = np.mean(norm_sigal)\n",
    "    mad_min = np.min(norm_sigal)\n",
    "    mad_median = np.median(norm_sigal)\n",
    "    mad_std = np.std(norm_sigal.astype(np.float64))#\n",
    "    logger.debug('mad max: {}'.format(mad_max))\n",
    "    logger.debug('mad mean: {}'.format(mad_mean))\n",
    "    logger.debug('mad min: {}'.format(mad_min))\n",
    "    logger.debug('mad median: {}'.format(mad_median))\n",
    "    logger.debug('mad std: {}'.format(mad_std))\n",
    "    norm_sigal=_normalize_signals(read[1])\n",
    "    rmad_max = np.max(norm_sigal)\n",
    "    rmad_mean = np.mean(norm_sigal)\n",
    "    rmad_min = np.min(norm_sigal)\n",
    "    rmad_median = np.median(norm_sigal)\n",
    "    rmad_std = np.std(norm_sigal.astype(np.float64))#\n",
    "    logger.debug('raw mad max: {}'.format(rmad_max))\n",
    "    logger.debug('raw mad mean: {}'.format(rmad_mean))\n",
    "    logger.debug('raw mad min: {}'.format(rmad_min))\n",
    "    logger.debug('raw mad median: {}'.format(rmad_median))\n",
    "    logger.debug('raw mad std: {}'.format(rmad_std))\n",
    "    td={'read id': read[0], 'raw max':rmax, 'raw mean':rmean, 'raw min':rmin, 'raw median':rmedian, \n",
    "                           'linalg.norm max':lmax, 'linalg.norm mean':lmean, 'linalg.norm min':lmin, 'linalg.norm median':lmedian,\n",
    "                           'remora max':re_max, 'remora mean':re_mean, 'remora min':re_min, 'remora median':re_median, 'remora std':re_std,\n",
    "                           'mad max':mad_max, 'mad mean':mad_mean, 'mad min':mad_min, 'mad median':mad_median, 'mad std':mad_std,\n",
    "                           'raw mad max':rmad_max, 'raw mad mean':rmad_mean, 'raw mad min':rmad_min, 'raw mad median':rmad_median, 'raw mad std':rmad_std}#\n",
    "    temp=pd.DataFrame(td, index=[0])\n",
    "    df = pd.concat([df,temp], ignore_index=True)\n",
    "    \n",
    "    logger.info('-------------------------------------------------------')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-256\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(abs(np.int8(-128))-128)\n",
    "print(abs(np.int16(-128))-128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
