{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pod5 as p5\n",
    "import pysam\n",
    "from multiprocessing import Queue#,Manager,Pool\n",
    "import time\n",
    "import os\n",
    "import signal\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "def handler(signum, frame):\n",
    "    print(\"hello world!\")\n",
    "signal.signal(signal.SIGPIPE, signal.SIG_IGN)  # 忽略SIGPIPE信号\n",
    "logger = logging.getLogger('test_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "test_log = logging.FileHandler('/home/xiaoyf/methylation/deepsignal/log/test.log','a',encoding='utf-8')\n",
    "formatter = logging.Formatter('%(asctime)s - %(filename)s - line:%(lineno)d - %(levelname)s - %(message)s -%(process)s') \n",
    "test_log.setFormatter(formatter)\n",
    "# 加载文件到logger对象中\n",
    "logger.addHandler(test_log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signal_from_pod5(pod5_path):\n",
    "    signals=[]\n",
    "    with p5.Reader(pod5_path) as reader:\n",
    "        for read_record in reader.reads():\n",
    "            #signals[str(read_record.read_id)] = {'signal':read_record.signal,'shift':read_record.calibration.offset,'scale':read_record.calibration.scale}#不加str会变成UUID，很奇怪\n",
    "            signals.append([str(read_record.read_id),read_record.signal.astype(np.float16),\n",
    "                            np.float16(read_record.calibration.offset),np.float16(read_record.calibration.scale)])\n",
    "            #0:read_id,1:signal,2:shift,3:scale\n",
    "    return signals\n",
    "def extract_move_from_bam(bam_path):\n",
    "    seq_move=[]\n",
    "    bamfile = pysam.AlignmentFile(bam_path, \"rb\",check_sq=False)\n",
    "    try:\n",
    "        for read in bamfile.fetch(until_eof=True):#暂时不使用索引，使用返回是空值\n",
    "            #print(read.query_name)\n",
    "            tags=dict(read.tags)\n",
    "            mv_tag=tags['mv']\n",
    "            ts_tag=tags['ts']\n",
    "            sm_tag=tags[\"sm\"]\n",
    "            sd_tag=tags[\"sd\"]\n",
    "            #read.update({read.query_name:{\"sequence\":read.query_sequence,\"stride\":mv_tag[0],\"mv_table\":np.array(mv_tag[1:]),\"num_trimmed\":ts_tag,\"shift\":sm_tag,\"scale\":sd_tag}})\n",
    "            seq_move.append([read.query_name,read.query_sequence,mv_tag[0],np.array(mv_tag[1:], dtype=np.int8),np.int8(ts_tag),np.float16(sm_tag),np.float16(sd_tag)])\n",
    "    except ValueError:\n",
    "        print('bam don\\'t has index')\n",
    "        for read in bamfile.fetch(until_eof=True,multiple_iterators=False):\n",
    "            tags=dict(read.tags)\n",
    "            mv_tag=tags['mv']\n",
    "            ts_tag=tags['ts']\n",
    "            sm_tag=tags[\"sm\"]\n",
    "            sd_tag=tags[\"sd\"]\n",
    "            seq_move.append([read.query_name,read.query_sequence,mv_tag[0],np.array(mv_tag[1:], dtype=np.int8),np.int8(ts_tag),np.float16(sm_tag),np.float16(sd_tag)])\n",
    "            #0:read_id,1:sequence,2:stride,3:mv_table,4:num_trimmed,5:to_norm_shift,6:to_norm_scale\n",
    "            #read[read.query_name] = {\"sequence\":read.query_sequence,\"stride\":mv_tag[0],\"mv_table\":np.array(mv_tag[1:]),\"num_trimmed\":ts_tag,\"shift\":sm_tag,\"scale\":sd_tag}\n",
    "    return seq_move\n",
    "def read_from_pod5_bam(pod5_path,bam_path,read_id=None):\n",
    "    read=[]\n",
    "    signal = extract_signal_from_pod5(pod5_path)\n",
    "    seq_move = extract_move_from_bam(bam_path)\n",
    "    if read_id is not None:\n",
    "        for i in range(len(seq_move)):\n",
    "            if seq_move[i][0]==read_id:\n",
    "                if seq_move[i][1] is not None:\n",
    "                    for j in range(len(signal)):\n",
    "                        if signal[j][0]==seq_move[i][0]:\n",
    "                            read.append([signal[j][0],signal[j][1],signal[j][2],signal[j][3],\n",
    "                            seq_move[i][1],seq_move[i][2],seq_move[i][3],seq_move[i][4],seq_move[i][5],seq_move[i][6]])\n",
    "        \n",
    "    else:\n",
    "        for i in range(len(seq_move)):\n",
    "            if seq_move[i][1] is not None:\n",
    "                for j in range(len(signal)):\n",
    "                    if signal[j][0]==seq_move[i][0]:\n",
    "                        read.append([signal[j][0],signal[j][1],signal[j][2],signal[j][3],\n",
    "                        seq_move[i][1],seq_move[i][2],seq_move[i][3],seq_move[i][4],seq_move[i][5],seq_move[i][6]])\n",
    "                #0:read_id,1:signal,2:to_pA_shift,3:to_pA_scale,4:sequence,5:stride,6:mv_table,7:num_trimmed,8:to_norm_shift,9:to_norm_scale\n",
    "                    \n",
    "                \n",
    "    return read\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod5_path = '/homeb/xiaoyf/data/HG002/example/pod5/output.pod5'\n",
    "signal=extract_signal_from_pod5(pod5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signal_from_pod5_raw(pod5_path):\n",
    "    signals=[]\n",
    "    with p5.Reader(pod5_path) as reader:\n",
    "        for read_record in reader.reads():\n",
    "            #signals[str(read_record.read_id)] = {'signal':read_record.signal,'shift':read_record.calibration.offset,'scale':read_record.calibration.scale}#不加str会变成UUID，很奇怪\n",
    "            signals.append([str(read_record.read_id),read_record.signal,\n",
    "                            read_record.calibration.offset,read_record.calibration.scale])\n",
    "    return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33920\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33920\n"
     ]
    }
   ],
   "source": [
    "signal_raw=extract_signal_from_pod5_raw(pod5_path)\n",
    "print(sys.getsizeof(signal_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "6\n",
      "80\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "my_list = [np.float16(1.0), np.float16(2.0), np.float16(3.0)]\n",
    "print(sys.getsizeof(my_list))\n",
    "my_array = np.array(my_list)\n",
    "print(my_array.nbytes)\n",
    "\n",
    "my_list = [1.0, 1.0, 1.0]\n",
    "print(sys.getsizeof(my_list))\n",
    "my_array = np.array(my_list)\n",
    "print(my_array.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam_path = '/homeb/xiaoyf/data/HG002/example/bam/sorted_has_moves.bam'\n",
    "bamfile = pysam.AlignmentFile(bam_path, \"rb\",check_sq=False)\n",
    "bamfile.has_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for read in bamfile.get_index_statistics():\n",
    "    #print(read)\n",
    "    print(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for read in bamfile:\n",
    "    print(read.query_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_and_move_table=extract_move_from_bam(bam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for '/homeb/xiaoyf/data/HG002/example/bam/has_moves.bam'\n"
     ]
    }
   ],
   "source": [
    "pod5_path = '/homeb/xiaoyf/data/HG002/example/pod5/output.pod5'\n",
    "bam_path = '/homeb/xiaoyf/data/HG002/example/bam/has_moves.bam'\n",
    "read=read_from_pod5_bam(pod5_path,bam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3239b4d9-0a7e-471c-86fe-e156b9f279a0',\n",
       " array([1284, 1066, 1050, ..., 1008, 1023,  920], dtype=int16),\n",
       " -243.0,\n",
       " 0.1462070643901825,\n",
       " 'ATGTATATGTAACCTACTTGGTTCAGTTACGTACTGCTGAATAAGTCTCACAATATTGATGGCTTTAAAGAGAGAAGTCCCCGGCCGGGCTGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCAAGGCAGGAGGATCACCTGAGGTCAAGAGTTCGAGACCAGCCTGGCCAACATGGTGAAACCTCCTCTCTACTAAAAATACAAAAATTAGCCAGGCATGGTGGCAGGTGCCTGTAATCCCAGCTACTTGGGAGGCTGAGGCAGGAGAATTGCTTGAACCTGGGAGGCAGAGATTGCAGTGAGCTGAGATCCCGCCACTGCAGTCCAGCCTGGGGGACAAGCAATACGTT',\n",
       " 5,\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 1, 1, 0, 0], dtype=int8),\n",
       " 10,\n",
       " 101.37413024902344,\n",
       " 28.20626449584961]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature=caculate_feature_one_one_for_each_base(read,21)\n",
    "#feature['0000b1ad-fdaf-49e6-bc11-cbe93270e3a3'][0].keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_keys(['signal', 'std', 'mean', 'num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_q=Queue()\n",
    "_prepare_read(read_q,read,batch_size=1000)\n",
    "read_batch=read_q.get()\n",
    "for read_id in read_batch:\n",
    "    print(read_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract_feature:   0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "#caculate_bar=tqdm(total = read_number, desc='extract_feature', position=0)\n",
    "#write_feature_bar=tqdm(total = read_number, desc='write_feature', position=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iupac_alphabets = {'A': ['A'], 'T': ['T'], 'C': ['C'], 'G': ['G'],\n",
    "                   'R': ['A', 'G'], 'M': ['A', 'C'], 'S': ['C', 'G'],\n",
    "                   'Y': ['C', 'T'], 'K': ['G', 'T'], 'W': ['A', 'T'],\n",
    "                   'B': ['C', 'G', 'T'], 'D': ['A', 'G', 'T'],\n",
    "                   'H': ['A', 'C', 'T'], 'V': ['A', 'C', 'G'],\n",
    "                   'N': ['A', 'C', 'G', 'T']}\n",
    "iupac_alphabets_rna = {'A': ['A'], 'C': ['C'], 'G': ['G'], 'U': ['U'],\n",
    "                       'R': ['A', 'G'], 'M': ['A', 'C'], 'S': ['C', 'G'],\n",
    "                       'Y': ['C', 'U'], 'K': ['G', 'U'], 'W': ['A', 'U'],\n",
    "                       'B': ['C', 'G', 'U'], 'D': ['A', 'G', 'U'],\n",
    "                       'H': ['A', 'C', 'U'], 'V': ['A', 'C', 'G'],\n",
    "                       'N': ['A', 'C', 'G', 'U']}\n",
    "def get_refloc_of_methysite_in_motif(seqstr, motifset, methyloc_in_motif=0)->list:\n",
    "    \"\"\"\n",
    "\n",
    "    :param seqstr:\n",
    "    :param motifset:\n",
    "    :param methyloc_in_motif: 0-based\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    motifset = set(motifset)\n",
    "    strlen = len(seqstr)\n",
    "    motiflen = len(list(motifset)[0])\n",
    "    sites = []\n",
    "    for i in range(0, strlen - motiflen + 1):\n",
    "        if seqstr[i:i + motiflen] in motifset:\n",
    "            sites.append(i+methyloc_in_motif)\n",
    "    return sites\n",
    "\n",
    "\n",
    "def _convert_motif_seq(ori_seq, is_dna=True):\n",
    "    outbases = []\n",
    "    for bbase in ori_seq:\n",
    "        if is_dna:\n",
    "            outbases.append(iupac_alphabets[bbase])\n",
    "        else:\n",
    "            outbases.append(iupac_alphabets_rna[bbase])\n",
    "\n",
    "    def recursive_permute(bases_list):\n",
    "        if len(bases_list) == 1:\n",
    "            return bases_list[0]\n",
    "        elif len(bases_list) == 2:\n",
    "            pseqs = []\n",
    "            for fbase in bases_list[0]:\n",
    "                for sbase in bases_list[1]:\n",
    "                    pseqs.append(fbase + sbase)\n",
    "            return pseqs\n",
    "        else:\n",
    "            pseqs = recursive_permute(bases_list[1:])\n",
    "            pseq_list = [bases_list[0], pseqs]\n",
    "            return recursive_permute(pseq_list)\n",
    "    return recursive_permute(outbases)\n",
    "\n",
    "\n",
    "def get_motif_seqs(motifs, is_dna=True):\n",
    "    ori_motif_seqs = motifs.strip().split(',')\n",
    "\n",
    "    motif_seqs = []\n",
    "    for ori_motif in ori_motif_seqs:\n",
    "        motif_seqs += _convert_motif_seq(ori_motif.strip().upper(), is_dna)\n",
    "    return motif_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(feature,index,nbase,nstd,nmean,nsig,num,fill_num=1):\n",
    "    nbase.append((feature[index][5])*num*fill_num)\n",
    "    nstd.append((feature[index][2])*num*fill_num)\n",
    "    nmean.append((feature[index][3])*num*fill_num)\n",
    "    nsig.append(random.sample(feature[index][1],num)*fill_num)\n",
    "    #return nbase,nstd,nmean,nsig\n",
    "\n",
    "#0:read_id,1:signal,2:std,3:mean,4:num,5:base \n",
    "def _get_neighbord_feature(sequence,feature,base_num)->list:\n",
    "    #数据预处理主要速度瓶颈，同样的reads数，不运行这个函数大概快了十倍，从二十多分钟减到两分钟\n",
    "    motif='CG'\n",
    "    max_sites=15\n",
    "    motif_seqs = get_motif_seqs(motif)\n",
    "    tsite_locs = get_refloc_of_methysite_in_motif(sequence, set(motif_seqs))\n",
    "    if len(tsite_locs)>max_sites:\n",
    "        tsite_locs = np.random.choice(\n",
    "                tsite_locs,\n",
    "                size=max_sites,\n",
    "                replace=False,\n",
    "            )\n",
    "    \n",
    "    nfeature=[]\n",
    "    windows_size=base_num-1//2\n",
    "    signal_sample=5\n",
    "    for i in range(len(feature)):\n",
    "        nbase=[]\n",
    "        nstd=[]\n",
    "        nmean=[]\n",
    "        nsig=[]\n",
    "        if i not in tsite_locs:\n",
    "            continue\n",
    "        #更改扩增逻辑，增添采样函数\n",
    "        #remora一条read好像只提取15个点\n",
    "        #if feature[i][4]>base_num:\n",
    "        #    logger.info(\"base correspoding signal number {} is more than window size {}\".format(feature[i][4],base_num))\n",
    "            \n",
    "        if i<windows_size:                   \n",
    "            if i!=0:\n",
    "                for k in range(i):\n",
    "                    expand(feature,k,nbase,nstd,nmean,nsig,signal_sample)\n",
    "            expand(feature,i,nbase,nstd,nmean,nsig,signal_sample,windows_size-i)\n",
    "            expand(feature,i,nbase,nstd,nmean,nsig,signal_sample)\n",
    "            for k in range(i,i+windows_size):\n",
    "                expand(feature,k,nbase,nstd,nmean,nsig,signal_sample)\n",
    "        elif (len(feature[i])-1)-i<windows_size:\n",
    "            for k in range(i-windows_size,i):\n",
    "                expand(feature,k,nbase,nstd,nmean,nsig,signal_sample)\n",
    "            expand(feature,i,nbase,nstd,nmean,nsig,signal_sample)                   \n",
    "            if i!=len(feature[i])-1:\n",
    "                for k in range(i,len(feature[i])-1):\n",
    "                    expand(feature,k,nbase,nstd,nmean,nsig,signal_sample)\n",
    "            expand(feature,i,nbase,nstd,nmean,nsig,signal_sample,windows_size-((len(feature[i])-1)-i))\n",
    "        else:\n",
    "            for k in range(i-windows_size,i):\n",
    "                expand(feature,k,nbase,nstd,nmean,nsig,signal_sample)\n",
    "            expand(feature,i,nbase,nstd,nmean,nsig,signal_sample)\n",
    "            for k in range(i,i+windows_size):\n",
    "                expand(feature,k,nbase,nstd,nmean,nsig,signal_sample)\n",
    "        #feature[read_id][i].update({'nbase':nbase,'nsig':nsig,'nstd':nstd,'nmean':nmean})\n",
    "        nfeature.append([feature[i][0],nbase,nsig,nstd,nmean])\n",
    "        \n",
    "        #0:read_id,1:nbase,2:nsig,3:nstd,4:nmean\n",
    "        #logger.debug('feature id: {}, feature:{}'.format(str(feature[0]),(str(nbase),str(nsig),str(nstd),str(nmean))))\n",
    "    return nfeature\n",
    "        \n",
    "#0:read_id,1:signal,2:to_pA_shift,3:to_pA_scale,4:sequence,5:stride,6:mv_table,7:num_trimmed,8:to_norm_shift,9:to_norm_scale\n",
    "def norm_signal_read_id(signal):\n",
    "    shift_scale_norm=[]\n",
    "    signal_norm=[]\n",
    "    shift_scale_norm=[(signal[8]/signal[3])-signal[2],(signal[9]/signal[3])]\n",
    "    if signal[3]==0:\n",
    "        logger.error('to_pA_scale of read {} is 0').format(signal[0])\n",
    "    #0:shift,1:scale\n",
    "    num_trimmed=signal[7]\n",
    "    #print('num_trimmed:{} and signal:{}'.format(num_trimmed,signal[1]))\n",
    "    #print('shift:{} and scale:{}'.format(shift_scale_norm[0],shift_scale_norm[1]))\n",
    "    signal_norm=(signal[1][num_trimmed:] - shift_scale_norm[0]) / shift_scale_norm[1]\n",
    "    if shift_scale_norm[1]==0:\n",
    "        logger.error('scale of read {} is 0').format(signal[0])        \n",
    "    return signal_norm\n",
    "\n",
    "def caculate_batch_feature_for_each_base(read_q,feature_q,base_num=0):\n",
    "    #print(\"extrac_features process-{} starts\".format(os.getpid()))\n",
    "    logger.info(\"extrac_features process-{} starts\".format(os.getpid()))\n",
    "    read_num = 0\n",
    "    \n",
    "    while True:\n",
    "        if read_q.empty():\n",
    "            time.sleep(10)\n",
    "        read_batch=read_q.get()\n",
    "        if read_batch == \"kill\":\n",
    "            read_q.put(\"kill\")\n",
    "            break\n",
    "        read_num += len(read_batch)\n",
    "        #flag=0\n",
    "        #if len(read_batch)>1:\n",
    "        #    flag=1\n",
    "        #    pos=bar_q.get()\n",
    "        #    caculate_bar = tqdm(total = len(read_batch), desc='extract_feature', position=pos)\n",
    "        #    bar_q.put(pos+1)\n",
    "        #else:\n",
    "        #    flag=0\n",
    "                \n",
    "        for read_one in read_batch:\n",
    "            feature=[]\n",
    "        #    if flag == 1:\n",
    "        #        caculate_bar.update()\n",
    "            #print(read_one)            \n",
    "            sequence = read_one[4]\n",
    "            stride = read_one[5]\n",
    "            movetable = read_one[6]           \n",
    "            #num_trimmed = read[read_id]['num_trimmed']\n",
    "            trimed_signals = norm_signal_read_id(read_one)#筛掉背景信号,norm\n",
    "            move_pos = np.append(np.argwhere(movetable == 1).flatten(), len(movetable))\n",
    "            #print(len(move_pos))\n",
    "            \n",
    "            for move_idx in range(len(move_pos) - 1):\n",
    "                start, end = move_pos[move_idx], move_pos[move_idx + 1]\n",
    "                signal=trimed_signals[(start * stride):(end * stride)].tolist()\n",
    "                mean=np.mean(signal)\n",
    "                std=np.std(signal)\n",
    "                num=end-start\n",
    "                #print(move_idx)\n",
    "                feature.append([read_one[0],signal,str(std),str(mean),int(num*stride),sequence[move_idx]])\n",
    "                #0:read_id,1:signal,2:std,3:mean,4:num,5:base        \n",
    "                #feature[read_id].append({'signal':signal,'std':str(std),'mean':str(mean),'num':int(num*stride),'base':sequence[move_idx]})\n",
    "            if base_num!=0:\n",
    "                nfeature=_get_neighbord_feature(sequence,feature,base_num)\n",
    "                logger.debug(\"extract neigbor features for read_id:{}\".format(read_one[0]))\n",
    "                feature_q.put(nfeature)\n",
    "            #feature_q.put(feature)\n",
    "        #feature_q.append(feature)\n",
    "        \n",
    "        #print(\"extrac_features process-{} ending, proceed {} read batch\".format(os.getpid(), read_num))\n",
    "        logger.info(\"extrac_features process-{} ending, proceed {} read batch\".format(os.getpid(), read_num))\n",
    "        #if caculate_bar is not None:\n",
    "        #    caculate_bar.close()\n",
    "    #pbar.close()\n",
    "        \n",
    "\n",
    "def _prepare_read(read_q,read,batch_size=1000):\n",
    "    i=0\n",
    "    #j=0\n",
    "    read_batch=[]\n",
    "    for read_one in read:\n",
    "        read_batch.append(read_one)\n",
    "        i=i+1\n",
    "        #j=j+1\n",
    "        #if j==40:\n",
    "        #    break\n",
    "        if i==batch_size:\n",
    "            i=0\n",
    "            read_q.put(read_batch)\n",
    "            read_batch=[]\n",
    "    read_q.put(read_batch)\n",
    "    #print('total batch number is {}'.format((len(read)-1)//batch_size+1))\n",
    "    logger.info('total batch number is {}'.format((len(read)-1)//batch_size+1))\n",
    "    #return len(read)\n",
    "def write_feature(read_number,file,feature_q):\n",
    "    #print(\"write_process-{} starts\".format(os.getpid()))\n",
    "    logger.info(\"write_process-{} starts\".format(os.getpid()))\n",
    "    dataset=[]\n",
    "    #pos=bar_q.get()\n",
    "    write_feature_bar = tqdm(total = read_number, desc='extract feature', position=0,colour='green',unit=' read')\n",
    "    #bar_q.put(pos+1)\n",
    "    try:\n",
    "        with open('/home/xiaoyf/methylation/deepsignal/log/feature.txt','w') as f:\n",
    "            while True:\n",
    "                if feature_q.empty():\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "                features = feature_q.get()\n",
    "                if features == \"kill\":\n",
    "                    logger.info('write_process-{} finished'.format(os.getpid()))\n",
    "                    #np_data = np.array(dataset)\n",
    "                    #np.save('/home/xiaoyf/methylation/deepsignal/log/data.npy', np_data)\n",
    "                    #包含neigbor feature的40条reads保存成npy需要27.87GB，这个开销是无法忍受的\n",
    "                    #print('write_process-{} finished'.format(os.getpid()))                \n",
    "                    break\n",
    "                logger.info('write process get neigbor features number:{}'.format(len(features)))\n",
    "                #logger.debug('feature id: {}'.format(str(features[0][0])))\n",
    "                for feature in features:\n",
    "                    #0:read_id,1:nbase,2:nsig,3:nstd,4:nmean\n",
    "                    #f.write(read_id+'\\t')\n",
    "                    write_feature_bar.update()\n",
    "                    dataset.append(feature)                \n",
    "                    f.write(str(feature[1])+'\\t'+str(feature[2])+\n",
    "                                '\\t'+str(feature[3])+'\\t'+str(feature[4])+'\\n')\n",
    "                    \n",
    "                f.flush()\n",
    "    except Exception as e:\n",
    "        logger.error('error in writing features, this always happend because memory not enough')\n",
    "        print(e)\n",
    "    finally:\n",
    "        write_feature_bar.close()\n",
    "def bar_listener(p_bar,desc='',position=1,number=4000):\n",
    "    bar = tqdm(total = number, desc=desc, position=position)\n",
    "    for item in iter(p_bar.get, None):\n",
    "        bar.update(item)\n",
    "\n",
    "def extract_feature(read,nproc = 4,batch_size=20):\n",
    "    start = time.time()\n",
    "    feature_q = Queue()\n",
    "    read_q=Queue()\n",
    "    #bar=Queue()\n",
    "    #bar.put(0)\n",
    "    #caculate_batch_feature_pbar = Manager().Queue()\n",
    "    #write_pbar = Manager().Queue()\n",
    "    _prepare_read(read_q,read,batch_size)\n",
    "    read_number=len(read)\n",
    "    feature_procs=[]  \n",
    "    read_q.put(\"kill\")\n",
    "    \n",
    "    #extract_feature_bar = mp.Process(target=bar_listener, args=(caculate_batch_feature_pbar, \"extract_features\", 1,))\n",
    "    #extract_feature_bar.daemon = True\n",
    "    #extract_feature_bar.start()\n",
    "    \n",
    "    \n",
    "    for _ in range(nproc):\n",
    "        p = mp.Process(target=caculate_batch_feature_for_each_base, args=(read_q,feature_q,21,))\n",
    "        p.daemon = True\n",
    "        p.start()\n",
    "        feature_procs.append(p)\n",
    "        \n",
    "               \n",
    "    \n",
    "    write_filename='/home/xiaoyf/methylation/deepsignal/log/data.npy'\n",
    "    \n",
    "    #write_feature_bar = mp.Process(target=bar_listener, args=(write_pbar, \"write_features\", 2,))\n",
    "    #write_feature_bar.daemon = True\n",
    "    #write_feature_bar.start()\n",
    "    #tqdm(total = 4000, desc=\"write_features\", position=1)\n",
    "    \n",
    "    p_w = mp.Process(target=write_feature, args=(read_number,write_filename,feature_q,))\n",
    "    p_w.daemon = True\n",
    "    p_w.start()\n",
    "    #with tqdm(total = read_number, desc='extract_feature', position=0) as pbar:\n",
    "    for p in feature_procs:\n",
    "        p.join()\n",
    "    \n",
    "    #caculate_bar.close()\n",
    "    #while True:\n",
    "    #    flag=0\n",
    "    #    for p in feature_procs:\n",
    "    #        if not p.is_alive():\n",
    "    #            flag+=1\n",
    "    #    if flag==0:\n",
    "    #        break\n",
    "    #    if flag!=0 and not p_w.is_alive():\n",
    "    #        logger.error(\"p_w terminate error\")\n",
    "    #        p_w.join()\n",
    "    #        p_w.start()\n",
    "    feature_q.put(\"kill\")\n",
    "    p_w.join()\n",
    "    #write_feature_bar.close()\n",
    "    \n",
    "    #extract_feature_bar.join()\n",
    "    #write_feature_bar.join()\n",
    "    #print(\"[main]extract_features costs %.1f seconds..\" %(time.time() - start))\n",
    "    logger.info(\"[main]extract_features costs %.1f seconds..\" %(time.time() - start))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###logging,tqdm,yeld,detopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract feature:  28%|\u001b[32m██▊       \u001b[0m| 1126/4000 [01:39<01:45, 27.31 read/s]/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "extract feature:  49%|\u001b[32m████▉     \u001b[0m| 1957/4000 [02:22<01:09, 29.43 read/s]/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "extract feature:  85%|\u001b[32m████████▌ \u001b[0m| 3411/4000 [03:10<00:23, 24.80 read/s]Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_122622/3872598850.py\", line 124, in caculate_batch_feature_for_each_base\n",
      "    nfeature=_get_neighbord_feature(sequence,feature,base_num)\n",
      "  File \"/tmp/ipykernel_122622/3872598850.py\", line 47, in _get_neighbord_feature\n",
      "    expand(feature,k,nbase,nstd,nmean,nsig,signal_sample)\n",
      "  File \"/tmp/ipykernel_122622/3872598850.py\", line 5, in expand\n",
      "    nsig.append(random.sample(feature[index][1],num)*fill_num)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/random.py\", line 363, in sample\n",
      "    raise ValueError(\"Sample larger than population or is negative\")\n",
      "ValueError: Sample larger than population or is negative\n",
      "extract feature:  93%|\u001b[32m█████████▎\u001b[0m| 3724/4000 [03:39<01:05,  4.22 read/s]Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_122622/3872598850.py\", line 124, in caculate_batch_feature_for_each_base\n",
      "    nfeature=_get_neighbord_feature(sequence,feature,base_num)\n",
      "  File \"/tmp/ipykernel_122622/3872598850.py\", line 47, in _get_neighbord_feature\n",
      "    expand(feature,k,nbase,nstd,nmean,nsig,signal_sample)\n",
      "  File \"/tmp/ipykernel_122622/3872598850.py\", line 5, in expand\n",
      "    nsig.append(random.sample(feature[index][1],num)*fill_num)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/random.py\", line 363, in sample\n",
      "    raise ValueError(\"Sample larger than population or is negative\")\n",
      "ValueError: Sample larger than population or is negative\n",
      "extract feature:  94%|\u001b[32m█████████▎\u001b[0m| 3741/4000 [03:49<00:15, 16.28 read/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 405, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/xiaoyf/anaconda3/envs/deepsignal/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    extract_feature(read,2,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[1.0244661829247577, 0.9674477248964478, 1.5635497861015053, 1.5791002746546807, 1.470246854782453, 0.22620777052841973, 0.8015758469959101, 0.5164835568543608, 0.5475845339607116, 0.8482273126554363, -0.012233053953603284, 0.04996890025909838, 0.060335892627881985, 0.1743728086845017, 0.10180386210301642, -0.40099526778298866, 0.6875389309392904, 0.37652915987578206, 0.029234915521531155, 0.21584077815963612, -0.3336098173858952, 0.5994194958046297, 0.14327183157815085, 0.5683185186982789, -0.8778769167470347, 0.5475845339607116, -0.9919138328036544, -0.03815053487556231, 0.22102427434402794, 0.24694175526598697, 0.5579515263294953, 0.5475845339607116, 0.537217541591928, 0.4957495721167936, 0.3920796484289575, 0.48538257974800997, 0.13290483920936724, 0.26767574000355415, -0.06925151198191314, 0.008500930783963936, 0.1951067934220689, -0.21438940514488367, 0.0033174345995721317, -0.29214184791076075, -0.29732534409515254, 0.39726314461334933, 0.42318062553530833, -0.0018660615848196732, -0.33879331357028697, 0.5061165644855772, 0.44909810645726733, 0.4905660759324018, 0.3817126560601739, 0.5320340454075362, 0.41799712935091654, 0.6201534805421969, 0.5061165644855772, 0.7652913737051674, 0.5994194958046297, 0.5994194958046297, -1.214804168732502, -1.188886687810543, -1.240721649654461, -1.2977401076827708, -1.1422352221510168, -1.292556611498379, -1.188886687810543, -1.3651255580798642, -1.4117770237393905, -1.344391573342297, -1.3651255580798642, 0.5424010377763199, 0.21584077815963612, 0.5320340454075362, 0.537217541591928, -0.6601700770025789, 0.15363882394693448, 0.30914370947868863, 0.16918931250010988, 0.11735435065619183, -0.9867303366192626, -1.1992536801793265, -0.9348953747753446, -0.841592443456292, -0.8986109014846019, -1.111134245044666, -1.1163177412290577, -1.0955837564914905, -1.0437487946475725, -1.1215012374134494, -0.25067387843562633, -0.9556293595129117, -1.1215012374134494, 0.6564379538329396, -1.111134245044666, 0.6460709614641559, 0.7290069004144248, 0.6097864881734133, 0.6564379538329396, 0.6253369767265887, 0.1951067934220689, 0.4024466407977411, 0.6305204729109806, 0.6201534805421969, 0.2935932209255132, 0.33506119040064763, 0.272859236187946, 0.2832262285567296, 0.2935932209255132, 0.30914370947868863, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\u001b[39m'\u001b[39;49m\u001b[39m/home/xiaoyf/methylation/deepsignal/log/feature.txt\u001b[39;49m\u001b[39m'\u001b[39;49m,dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mstr,float,float,float,str\u001b[39;49m\u001b[39m'\u001b[39;49m,delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/lib/npyio.py:1163\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1160\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrong number of columns at line \u001b[39m\u001b[39m{\u001b[39;00mlineno\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1161\u001b[0m     \u001b[39m# Convert each value according to its column, then pack it\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[39m# according to the dtype's nesting, and store it.\u001b[39;00m\n\u001b[0;32m-> 1163\u001b[0m     chunk\u001b[39m.\u001b[39mappend(packer(convert_row(words)))\n\u001b[1;32m   1164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:  \u001b[39m# The islice is empty, i.e. we're done.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/lib/npyio.py:1145\u001b[0m, in \u001b[0;36mloadtxt.<locals>.convert_row\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_row\u001b[39m(vals):\n\u001b[0;32m-> 1145\u001b[0m     \u001b[39mreturn\u001b[39;00m [conv(val) \u001b[39mfor\u001b[39;00m conv, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(converters, vals)]\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/lib/npyio.py:1145\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_row\u001b[39m(vals):\n\u001b[0;32m-> 1145\u001b[0m     \u001b[39mreturn\u001b[39;00m [conv(val) \u001b[39mfor\u001b[39;00m conv, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(converters, vals)]\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsignal/lib/python3.8/site-packages/numpy/lib/npyio.py:725\u001b[0m, in \u001b[0;36m_floatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_floatconv\u001b[39m(x):\n\u001b[1;32m    724\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 725\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39;49m(x)  \u001b[39m# The fastest path.\u001b[39;00m\n\u001b[1;32m    726\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m0x\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m x:  \u001b[39m# Don't accidentally convert \"a\" (\"0xa\") to 10.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[1.0244661829247577, 0.9674477248964478, 1.5635497861015053, 1.5791002746546807, 1.470246854782453, 0.22620777052841973, 0.8015758469959101, 0.5164835568543608, 0.5475845339607116, 0.8482273126554363, -0.012233053953603284, 0.04996890025909838, 0.060335892627881985, 0.1743728086845017, 0.10180386210301642, -0.40099526778298866, 0.6875389309392904, 0.37652915987578206, 0.029234915521531155, 0.21584077815963612, -0.3336098173858952, 0.5994194958046297, 0.14327183157815085, 0.5683185186982789, -0.8778769167470347, 0.5475845339607116, -0.9919138328036544, -0.03815053487556231, 0.22102427434402794, 0.24694175526598697, 0.5579515263294953, 0.5475845339607116, 0.537217541591928, 0.4957495721167936, 0.3920796484289575, 0.48538257974800997, 0.13290483920936724, 0.26767574000355415, -0.06925151198191314, 0.008500930783963936, 0.1951067934220689, -0.21438940514488367, 0.0033174345995721317, -0.29214184791076075, -0.29732534409515254, 0.39726314461334933, 0.42318062553530833, -0.0018660615848196732, -0.33879331357028697, 0.5061165644855772, 0.44909810645726733, 0.4905660759324018, 0.3817126560601739, 0.5320340454075362, 0.41799712935091654, 0.6201534805421969, 0.5061165644855772, 0.7652913737051674, 0.5994194958046297, 0.5994194958046297, -1.214804168732502, -1.188886687810543, -1.240721649654461, -1.2977401076827708, -1.1422352221510168, -1.292556611498379, -1.188886687810543, -1.3651255580798642, -1.4117770237393905, -1.344391573342297, -1.3651255580798642, 0.5424010377763199, 0.21584077815963612, 0.5320340454075362, 0.537217541591928, -0.6601700770025789, 0.15363882394693448, 0.30914370947868863, 0.16918931250010988, 0.11735435065619183, -0.9867303366192626, -1.1992536801793265, -0.9348953747753446, -0.841592443456292, -0.8986109014846019, -1.111134245044666, -1.1163177412290577, -1.0955837564914905, -1.0437487946475725, -1.1215012374134494, -0.25067387843562633, -0.9556293595129117, -1.1215012374134494, 0.6564379538329396, -1.111134245044666, 0.6460709614641559, 0.7290069004144248, 0.6097864881734133, 0.6564379538329396, 0.6253369767265887, 0.1951067934220689, 0.4024466407977411, 0.6305204729109806, 0.6201534805421969, 0.2935932209255132, 0.33506119040064763, 0.272859236187946, 0.2832262285567296, 0.2935932209255132, 0.30914370947868863, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132, 0.35061167895382306, 0.272859236187946, 0.2780427323723378, 0.26767574000355415, 0.2935932209255132]'"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.loadtxt('/home/xiaoyf/methylation/deepsignal/log/feature.txt',dtype='str,float,float,float,str',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(nproc = 4):\n",
    "    start = time.time()\n",
    "    feature_q = Queue()\n",
    "    read_q=Queue()\n",
    "    _prepare_read(read_q,read,batch_size=20)\n",
    "    feature_procs=[]  \n",
    "    read_q.put(\"kill\")\n",
    "    caculate_batch_feature_pbar = Queue()\n",
    "    extract_feature_bar = mp.Process(target=bar_listener, args=(caculate_batch_feature_pbar, \"extract_features\", 1,))\n",
    "    extract_feature_bar.daemon = True\n",
    "    extract_feature_bar.start()\n",
    "    for _ in range(nproc):\n",
    "        p = mp.Process(target=caculate_batch_feature_for_each_base, args=(caculate_batch_feature_pbar,read_q,feature_q,21,))\n",
    "        p.daemon = True\n",
    "        p.start()\n",
    "        feature_procs.append(p)\n",
    "    \n",
    "    write_filename='/home/xiaoyf/methylation/deepsignal/log/feature.txt'\n",
    "    write_pbar = Queue()\n",
    "    write_feature_bar = mp.Process(target=bar_listener, args=(write_pbar, \"write_features\", 2,))\n",
    "    write_feature_bar.daemon = True\n",
    "    write_feature_bar.start()\n",
    "    #tqdm(total = 4000, desc=\"write_features\", position=1)\n",
    "    p_w = mp.Process(target=write_feature, args=(write_pbar,write_filename,feature_q,))\n",
    "    p_w.daemon = False\n",
    "    p_w.start()\n",
    "\n",
    "    for p in feature_procs:\n",
    "        p.join()\n",
    "\n",
    "    feature_q.put(\"kill\")\n",
    "    p_w.join()\n",
    "    write_pbar.put(None)\n",
    "    caculate_batch_feature_pbar.put(None)\n",
    "    extract_feature_bar.join()\n",
    "    write_feature_bar.join()\n",
    "    #print(\"[main]extract_features costs %.1f seconds..\" %(time.time() - start))\n",
    "    logger.info(\"[main]extract_features costs %.1f seconds..\" %(time.time() - start))\n",
    "def write_feature(file,feature_q):\n",
    "    #print(\"write_process-{} starts\".format(os.getpid()))\n",
    "    logger.info(\"write_process-{} starts\".format(os.getpid()))\n",
    "    dataset=[]\n",
    "    try:\n",
    "        with open(file,'w') as f:\n",
    "            while True:\n",
    "                if feature_q.empty():\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "                features = feature_q.get()\n",
    "                if features == \"kill\":\n",
    "                    logger.info('write_process-{} finished'.format(os.getpid()))\n",
    "                    np_data = np.array(dataset)\n",
    "                    np.save('/home/xiaoyf/methylation/deepsignal/log/data.npy', np_data)\n",
    "                    #包含neigbor feature的40条reads保存成npy需要27.87GB，这个开销是无法忍受的\n",
    "                    #print('write_process-{} finished'.format(os.getpid()))                \n",
    "                    break\n",
    "                logger.info('write process get neigbor features number:{}'.format(len(features)))\n",
    "                #logger.debug('feature id: {}'.format(str(features[0][0])))\n",
    "                for feature in features:\n",
    "                    #0:read_id,1:nbase,2:nsig,3:nstd,4:nmean\n",
    "                    #f.write(read_id+'\\t')\n",
    "                    write_feature_bar.update()\n",
    "                    dataset.append(feature[1:])                \n",
    "                    #f.write(str(feature[1])+'\\t'+str(feature[2])+\n",
    "                    #            '\\t'+str(feature[3])+'\\t'+str(feature[4])+'\\n')\n",
    "                    \n",
    "                f.flush()\n",
    "    except Exception as e:\n",
    "        logger.error('error in writing features')\n",
    "        print(e)\n",
    "    #write_pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:40<00:00,  9.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def listener(q): \n",
    "    pbar = tqdm(total = 1000) \n",
    "    while True:\n",
    "        if not q.empty():\n",
    "            k=q.get()\n",
    "            if k==1:\n",
    "                pbar.update(1)\n",
    "            else:\n",
    "                break\n",
    "    pbar.close()\n",
    "\n",
    "def solve(q):\n",
    "    for i in range(100):\n",
    "        time.sleep(1)\n",
    "        q.put(1)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    manage=mp.Manager()\n",
    "    q=manage.Queue()\n",
    "    p=mp.Process(target=listener,args=(q,))\n",
    "    p.start()\n",
    "    processList=[]\n",
    "    for i in range(10):\n",
    "        t=mp.Process(target=solve,args=(q,))\n",
    "        processList.append(t)\n",
    "        t.start()\n",
    "    for t in processList:\n",
    "        t.join()\n",
    "    q.put(-1)\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('/home/xiaoyf/methylation/deepsignal/log/data.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3239b4d9-0a7e-471c-86fe-e156b9f279a0',\n",
       "       list([0.8430438164710445, 0.8067593431803018, 0.7963923508115183, 0.7704748698895593, 0.8274933279178691]),\n",
       "       '0.025095831333870715', '0.8088327416540585', 5, 'T'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "all_kmer_levels = dict(\n",
    "        (\"\".join(bs), []) for bs in product(\"ACGT\", repeat=4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base2code_dna = {'A': 0, 'C': 1, 'G': 2, 'T': 3, 'N': 4,\n",
    "                 'W': 4, 'S': 4, 'M': 4, 'K': 4, 'R': 4,\n",
    "                 'Y': 4, 'B': 4, 'V': 4, 'D': 4, 'H': 4,\n",
    "                 'Z': 4}  # set 4 for all bases except ACGT, for now\n",
    "def norm_signal_read_id_dict(signal):\n",
    "    shift_scale_norm={}\n",
    "    signal_norm={}\n",
    "    shift_scale_norm={}\n",
    "    shift_scale_norm['shift']=(signal['to_norm_shift']/signal['to_pA_scale'])-signal['to_pA_shift']\n",
    "    shift_scale_norm['scale']=(signal['to_norm_scale']/signal['to_pA_scale'])\n",
    "    num_trimmed=signal[\"num_trimmed\"]\n",
    "    signal_norm=(signal['signal'][num_trimmed:] - shift_scale_norm['shift']) / shift_scale_norm['scale']        \n",
    "    return signal_norm\n",
    "\n",
    "def read_from_pod5_bam_dict(pod5_path,bam_path,read_id=None):\n",
    "    read={}\n",
    "    signal = extract_signal_from_pod5(pod5_path)\n",
    "    seq_move = extract_move_from_bam(bam_path)\n",
    "    if read_id is not None:\n",
    "        if seq_move[read_id]['sequence'] is not None:\n",
    "            if signal[read_id] is not None:\n",
    "                read[read_id]={\"sequence\":seq_move[read_id]['sequence'],\"signal\":signal[read_id]['signal'],'mv_table':seq_move[read_id]['mv_table'],\n",
    "                               \"num_trimmed\":seq_move[read_id]['num_trimmed'],\"to_norm_shift\":seq_move[read_id]['shift'],\n",
    "                               \"to_norm_scale\":seq_move[read_id]['scale'],\"stride\":seq_move[read_id]['stride'],\n",
    "                               'to_pA_shift':signal[read_id]['shift'],\n",
    "                               'to_pA_scale':signal[read_id][\"scale\"]}\n",
    "    else:\n",
    "        for read_id in seq_move.keys():\n",
    "            if seq_move[read_id]['sequence'] is not None:\n",
    "                if signal[read_id] is not None:\n",
    "                    read[read_id]={\"sequence\":seq_move[read_id]['sequence'],\"signal\":signal[read_id]['signal'],'mv_table':seq_move[read_id]['mv_table'],\n",
    "                               \"num_trimmed\":seq_move[read_id]['num_trimmed'],\"to_norm_shift\":seq_move[read_id]['shift'],\n",
    "                               \"to_norm_scale\":seq_move[read_id]['scale'],\"stride\":seq_move[read_id]['stride'],\n",
    "                               'to_pA_shift':signal[read_id]['shift'],\n",
    "                               'to_pA_scale':signal[read_id][\"scale\"]}\n",
    "    return read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_neighbord_feature_dict(feature,base_num):\n",
    "    windows_size=base_num-1//2\n",
    "    for read_id in feature.keys():\n",
    "        for i in range(len(feature[read_id])):\n",
    "            nbase=[]\n",
    "            nstd=[]\n",
    "            nmean=[]\n",
    "            nsig=[]\n",
    "            if i<windows_size:                   \n",
    "                if i!=0:\n",
    "                    for k in range(i):\n",
    "                        nbase=nbase+list(feature[read_id][k]['base'])*feature[read_id][k][\"num\"]\n",
    "                        nstd=nstd+list(feature[read_id][k]['std'])*feature[read_id][k]['num']\n",
    "                        nmean=nmean+list(feature[read_id][k]['mean'])*feature[read_id][k]['num']\n",
    "                        nsig=nsig+feature[read_id][k]['signal']\n",
    "                nbase=nbase+list(feature[read_id][i]['base'])*(windows_size-i)*feature[read_id][i]['num']\n",
    "                nbase=nbase+list(feature[read_id][i]['base'])*feature[read_id][i]['num']\n",
    "                nstd=nstd+list(feature[read_id][i]['std'])*(windows_size-i)*feature[read_id][i]['num']\n",
    "                nstd=nstd+list(feature[read_id][i]['std'])*feature[read_id][i]['num']\n",
    "                nmean=nmean+list(feature[read_id][i]['mean'])*(windows_size-i)*feature[read_id][i]['num']\n",
    "                nmean=nmean+list(feature[read_id][i]['mean'])*feature[read_id][i]['num']\n",
    "                for k in range(i,i+windows_size):\n",
    "                    nbase=nbase+list(feature[read_id][k]['base'])*feature[read_id][k]['num']\n",
    "                    nstd=nbase+list(feature[read_id][k]['std'])*feature[read_id][k]['num']\n",
    "                    nmean=nbase+list(feature[read_id][k]['mean'])*feature[read_id][k]['num']\n",
    "                nsig=nsig+feature[read_id][i]['signal']*(windows_size-i)\n",
    "                nsig=nsig+feature[read_id][i]['signal']\n",
    "                for k in range(i,i+windows_size):\n",
    "                    nsig=nsig+feature[read_id][k]['signal']\n",
    "            elif (len(feature[read_id])-1)-i<windows_size:\n",
    "                for k in range(i-windows_size,i):\n",
    "                    nbase=nbase+list(feature[read_id][k]['base'])*feature[read_id][k]['num']\n",
    "                    nstd=nstd+list(feature[read_id][k]['std'])*feature[read_id][k]['num']\n",
    "                    nmean=nmean+list(feature[read_id][k]['mean'])*feature[read_id][k]['num']\n",
    "                nbase=nbase+list(feature[read_id][i]['base'])*feature[read_id][i]['num']\n",
    "                nstd=nstd+list(feature[read_id][i]['std'])*feature[read_id][i]['num']\n",
    "                nmean=nmean+list(feature[read_id][i]['mean'])*feature[read_id][i]['num']\n",
    "                for k in range(i-windows_size,i):\n",
    "                    nsig=nsig+feature[read_id][k]['signal']\n",
    "                nsig=nsig+feature[read_id][i]['signal']                   \n",
    "                if i!=len(feature[read_id])-1:\n",
    "                    for k in range(i,len(feature[read_id])-1):\n",
    "                        nbase=nbase+list(feature[read_id][k]['base'])*feature[read_id][k]['num']\n",
    "                        nstd=nstd+list(feature[read_id][k]['std'])*feature[read_id][k]['num']\n",
    "                        nmean=nmean+list(feature[read_id][k]['mean'])*feature[read_id][k]['num']\n",
    "                        nsig=nsig+feature[read_id][k]['signal']\n",
    "                nbase=nbase+list(feature[read_id][i]['base'])*(windows_size-((len(feature[read_id])-1)-i))*feature[read_id][i]['num']\n",
    "                nstd=nstd+list(feature[read_id][i]['std'])*(windows_size-((len(feature[read_id])-1)-i))*feature[read_id][i]['num']\n",
    "                nmean=nmean+list(feature[read_id][i]['mean'])*(windows_size-((len(feature[read_id])-1)-i))*feature[read_id][i]['num']\n",
    "                nsig=nsig+feature[read_id][i]['signal']*(windows_size-((len(feature[read_id])-1)-i))\n",
    "            else:\n",
    "                for k in range(i-windows_size,i):\n",
    "                    nbase=nbase+list(feature[read_id][k]['base'])*feature[read_id][k]['num']\n",
    "                    nstd=nstd+list(feature[read_id][k]['std'])*feature[read_id][k]['num']\n",
    "                    nmean=nmean+list(feature[read_id][k]['mean'])*feature[read_id][k]['num']\n",
    "                    nsig=nsig+feature[read_id][k]['signal']\n",
    "                nbase=nbase+list(feature[read_id][i]['base'])*feature[read_id][i]['num']\n",
    "                nstd=nstd+list(feature[read_id][i]['std'])*feature[read_id][i]['num']\n",
    "                nmean=nmean+list(feature[read_id][i]['mean'])*feature[read_id][i]['num']\n",
    "                nsig=nsig+feature[read_id][i]['signal']\n",
    "                for k in range(i,i+windows_size):\n",
    "                    nbase=nbase+list(feature[read_id][k]['base'])*feature[read_id][k]['num']\n",
    "                    nstd=nstd+list(feature[read_id][k]['std'])*feature[read_id][k]['num']\n",
    "                    nmean=nmean+list(feature[read_id][k]['mean'])*feature[read_id][k]['num']\n",
    "                    nsig=nsig+feature[read_id][k]['signal']\n",
    "            feature[read_id][i].update({'nbase':nbase,'nsig':nsig,'nstd':nstd,'nmean':nmean})\n",
    "\n",
    "def caculate_batch_feature_for_each_base_dict(read_q,feature_q,base_num=0):\n",
    "    feature={}\n",
    "    print(\"extrac_features process-{} starts\".format(os.getpid()))\n",
    "    read_num = 0\n",
    "    while True:\n",
    "        if read_q.empty():\n",
    "            time.sleep(10)\n",
    "        read_batch=read_q.get()\n",
    "        if read_batch == \"kill\":\n",
    "            read_q.put(\"kill\")\n",
    "            break\n",
    "        read_num += len(read_batch)\n",
    "        for read_id in read_batch.keys():\n",
    "            feature[read_id]=[]\n",
    "            sequence = read_batch[read_id]['sequence']\n",
    "            movetable = read_batch[read_id]['mv_table']\n",
    "            stride = read_batch[read_id]['stride']\n",
    "            #num_trimmed = read[read_id]['num_trimmed']\n",
    "            trimed_signals = norm_signal_read_id(read_batch[read_id])#筛掉背景信号,norm\n",
    "            move_pos = np.append(np.argwhere(movetable == 1).flatten(), len(movetable))\n",
    "            #print(len(move_pos))\n",
    "            for move_idx in range(len(move_pos) - 1):\n",
    "                start, end = move_pos[move_idx], move_pos[move_idx + 1]\n",
    "                signal=trimed_signals[(start * stride):(end * stride)].tolist()\n",
    "                mean=np.mean(signal)\n",
    "                std=np.std(signal)\n",
    "                num=end-start\n",
    "                #print(move_idx)        \n",
    "                feature[read_id].append({'signal':signal,'std':str(std),'mean':str(mean),'num':int(num*stride),'base':sequence[move_idx]})\n",
    "        #feature_q.append(feature)\n",
    "        if base_num!=0:\n",
    "            _get_neighbord_feature(feature,base_num)\n",
    "        feature_q.put(feature)\n",
    "        print(\"extrac_features process-{} ending, proceed {} read batch\".format(os.getpid(), read_num))\n",
    "            \n",
    "        \n",
    "\n",
    "def _prepare_read_dict(read_q,read,batch_size=1000):\n",
    "    i=0\n",
    "    read_batch={}\n",
    "    for read_id in read.keys():\n",
    "        #print(read_id)\n",
    "        read_batch[read_id]={}\n",
    "        read_batch[read_id].update(read[read_id])\n",
    "        i=i+1\n",
    "        if i==batch_size:\n",
    "            i=0\n",
    "            read_q.put(read_batch)\n",
    "            read_batch={}\n",
    "    read_q.put(read_batch)\n",
    "\n",
    "def write_feature_dict(feature_q):\n",
    "    print(\"write_process-{} starts\".format(os.getpid()))\n",
    "    with open('/homeb/xiaoyf/data/HG002/example/feature.txt','w') as f:\n",
    "        while True:\n",
    "            if feature_q.empty():\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            feature = feature_q.get()\n",
    "            if feature == \"kill\":\n",
    "                print('write_process-{} finished'.format(os.getpid()))\n",
    "                break\n",
    "            for read_id in feature.keys():\n",
    "                #f.write(read_id+'\\t')\n",
    "                for i in range(len(feature[read_id])):\n",
    "                    f.write(str(feature[read_id][i]['nbase'])+'\\t'+str(feature[read_id][i]['nsig'])+'\\t'+str(feature[read_id][i]['nstd'])+\n",
    "                            '\\t'+str(feature[read_id][i]['nmean'])+'\\n')\n",
    "            f.flush()\n",
    "            \n",
    "        \n",
    "\n",
    "def extract_feature():\n",
    "    start = time.time()\n",
    "    feature_q = Queue()\n",
    "    read_q=Queue()\n",
    "    _prepare_read(read_q,read,batch_size=500)\n",
    "    feature_procs=[]\n",
    "    nproc = 4\n",
    "    read_q.put(\"kill\")\n",
    "    for _ in range(nproc):\n",
    "        p = mp.Process(target=caculate_batch_feature_for_each_base, args=(read_q,feature_q,21,))\n",
    "        p.daemon = True\n",
    "        p.start()\n",
    "        feature_procs.append(p)\n",
    "\n",
    "    p_w = mp.Process(target=write_feature, args=(feature_q,))\n",
    "    p_w.daemon = True\n",
    "    p_w.start()\n",
    "\n",
    "    for p in feature_procs:\n",
    "        p.join()\n",
    "\n",
    "    feature_q.put(\"kill\")\n",
    "    p_w.join()\n",
    "    print(\"[main]extract_features costs %.1f seconds..\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0:read_id,1:signal,2:std,3:mean,4:num,5:base \n",
    "def _get_neighbord_feature(sequence,feature,base_num):\n",
    "    #数据预处理主要速度瓶颈，同样的reads数，不运行这个函数大概快了十倍，从二十多分钟减到两分钟\n",
    "    motif='CG'\n",
    "    motif_seqs = get_motif_seqs(motif)\n",
    "    tsite_locs = get_refloc_of_methysite_in_motif(sequence, set(motif_seqs))\n",
    "    nfeature=[]\n",
    "    windows_size=base_num-1//2\n",
    "    for i in range(len(feature)):\n",
    "        nbase=[]\n",
    "        nstd=[]\n",
    "        nmean=[]\n",
    "        nsig=[]\n",
    "        if i not in tsite_locs:\n",
    "            continue\n",
    "        if i<windows_size:                   \n",
    "            if i!=0:\n",
    "                for k in range(i):\n",
    "                    nbase=nbase+list(feature[k][5])*signal_sample\n",
    "                    nstd=nstd+list(feature[k][2])*signal_sample\n",
    "                    nmean=nmean+list(feature[k][3])*signal_sample\n",
    "                    nsig=nsig+feature[k][1]\n",
    "            nbase=nbase+list(feature[i][5])*(windows_size-i)*signal_sample\n",
    "            nbase=nbase+list(feature[i][5])*signal_sample\n",
    "            nstd=nstd+list(feature[i][2])*(windows_size-i)*signal_sample\n",
    "            nstd=nstd+list(feature[i][2])*signal_sample\n",
    "            nmean=nmean+list(feature[i][3])*(windows_size-i)*signal_sample\n",
    "            nmean=nmean+list(feature[i][3])*signal_sample\n",
    "            nsig=nsig+feature[i][1]*(windows_size-i)\n",
    "            nsig=nsig+feature[i][1]\n",
    "            for k in range(i,i+windows_size):\n",
    "                nbase=nbase+list(feature[k][5])*signal_sample\n",
    "                nstd=nbase+list(feature[k][2])*signal_sample\n",
    "                nmean=nbase+list(feature[k][3])*signal_sample\n",
    "                nsig=nsig+feature[k][1]\n",
    "        elif (len(feature[i])-1)-i<windows_size:\n",
    "            for k in range(i-windows_size,i):\n",
    "                nbase=nbase+list(feature[k][5])*signal_sample\n",
    "                nstd=nstd+list(feature[k][2])*signal_sample\n",
    "                nmean=nmean+list(feature[k][3])*signal_sample\n",
    "                nsig=nsig+feature[k][1]\n",
    "            nbase=nbase+list(feature[i][5])*signal_sample\n",
    "            nstd=nstd+list(feature[i][2])*signal_sample\n",
    "            nmean=nmean+list(feature[i][3])*signal_sample        \n",
    "            nsig=nsig+feature[i][1]                   \n",
    "            if i!=len(feature[i])-1:\n",
    "                for k in range(i,len(feature[i])-1):\n",
    "                    nbase=nbase+list(feature[k][5])*signal_sample\n",
    "                    nstd=nstd+list(feature[k][2])*signal_sample\n",
    "                    nmean=nmean+list(feature[k][3])*signal_sample\n",
    "                    nsig=nsig+feature[k][1]\n",
    "            nbase=nbase+list(feature[i][5])*(windows_size-((len(feature[i])-1)-i))*signal_sample\n",
    "            nstd=nstd+list(feature[i][2])*(windows_size-((len(feature[i])-1)-i))*signal_sample\n",
    "            nmean=nmean+list(feature[i][3])*(windows_size-((len(feature[i])-1)-i))*signal_sample\n",
    "            nsig=nsig+feature[i][1]*(windows_size-((len(feature[i])-1)-i))\n",
    "        else:\n",
    "            for k in range(i-windows_size,i):\n",
    "                nbase=nbase+list(feature[k][5])*signal_sample\n",
    "                nstd=nstd+list(feature[k][2])*signal_sample\n",
    "                nmean=nmean+list(feature[k][3])*signal_sample\n",
    "                nsig=nsig+feature[k][1]\n",
    "            nbase=nbase+list(feature[i][5])*signal_sample\n",
    "            nstd=nstd+list(feature[i][2])*signal_sample\n",
    "            nmean=nmean+list(feature[i][3])*signal_sample\n",
    "            nsig=nsig+feature[i][1]\n",
    "            for k in range(i,i+windows_size):\n",
    "                nbase=nbase+list(feature[k][5])*signal_sample\n",
    "                nstd=nstd+list(feature[k][2])*signal_sample\n",
    "                nmean=nmean+list(feature[k][3])*signal_sample\n",
    "                nsig=nsig+feature[k][1]\n",
    "        #feature[read_id][i].update({'nbase':nbase,'nsig':nsig,'nstd':nstd,'nmean':nmean})\n",
    "        nfeature.append([feature[i][0],nbase,nsig,nstd,nmean])\n",
    "        \n",
    "        #0:read_id,1:nbase,2:nsig,3:nstd,4:nmean\n",
    "        #logger.debug('feature id: {}, feature:{}'.format(str(feature[0]),(str(nbase),str(nsig),str(nstd),str(nmean))))\n",
    "    return nfeature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
