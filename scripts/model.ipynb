{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m gzip\u001b[39m.\u001b[39mopen(\u001b[39m'\u001b[39m\u001b[39m/homeb/xiaoyf/data/HG002/R9.4/samples_CG.hc_poses.r30m.tsv.gz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrt\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread()\u001b[39m.\u001b[39mdecode()\n\u001b[1;32m      5\u001b[0m     tsv_reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(data, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     number_of_lines \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsignal/lib/python3.8/gzip.py:286\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39merrno\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(errno\u001b[39m.\u001b[39mEBADF, \u001b[39m\"\u001b[39m\u001b[39mread() on write-only GzipFile object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mread(size)\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import csv\n",
    "with gzip.open('/homeb/xiaoyf/data/HG002/R9.4/samples_CG.hc_poses.r30m.tsv.gz', 'rt') as f:\n",
    "    data = f.read().decode()\n",
    "    tsv_reader = csv.reader(data, delimiter=\"\\t\")\n",
    "\n",
    "    number_of_lines = 10\n",
    "\n",
    "    for i in range(number_of_lines):\n",
    "        row = next(tsv_reader)\n",
    "        print(i, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39182/2179687221.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  chunks = pd.read_csv('/homeb/xiaoyf/data/HG002/R9.4/samples_CG.hc_poses.r30m.tsv',sep='\\t',error_bad_lines=False,iterator = True,header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "chunks = pd.read_csv('/homeb/xiaoyf/data/HG002/R9.4/samples_CG.hc_poses.r30m.tsv',sep='\\t',error_bad_lines=False,iterator = True,header=None)\n",
    "chunk = chunks.get_chunk(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在deepsignal2里面一个碱基固定对应16个信号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 16)\n",
      "(17, 16)\n",
      "(17, 16)\n",
      "(17, 16)\n",
      "(17, 16)\n"
     ]
    }
   ],
   "source": [
    "sigs=chunk.iloc[:,-2]\n",
    "for s in sigs:\n",
    "    sig=np.array([[float(y) for y in x.split(\",\")] for x in s.split(\";\")])\n",
    "    print(sig.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--conv-in\", type=int, default=4, help=\"Input sequence features\"\n",
    "    )\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=512, required=False)\n",
    "    parser.add_argument(\"--step_interval\", type=int, default=100, required=False)\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001, required=False)\n",
    "    parser.add_argument(\n",
    "        \"--train-file\",\n",
    "        type=str,\n",
    "        help=\"feature file used in trainning\",\n",
    "        default=\"/homeb/xiaoyf/data/HG002/R9.4/samples_CG.hc_poses.r30m.tsv\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_dir\", type=str, default=\"/home/xiaoyf/methylation/deepsignal/log/\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_epoch_num\",\n",
    "        action=\"store\",\n",
    "        default=10,\n",
    "        type=int,\n",
    "        required=False,\n",
    "        help=\"max epoch num, default 10\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min_epoch_num\",\n",
    "        action=\"store\",\n",
    "        default=5,\n",
    "        type=int,\n",
    "        required=False,\n",
    "        help=\"min epoch num, default 5\",\n",
    "    )\n",
    "    return parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(tensor, dim=-1):\n",
    "    squared_norm = (tensor**2).sum(dim=dim, keepdim=True)\n",
    "    scale = squared_norm / (1 + squared_norm)\n",
    "    return scale * tensor / torch.sqrt(squared_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squash(nn.Module):\n",
    "    def __init__(self, eps=10e-21, **kwargs):\n",
    "        super(Squash, self).__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, s):\n",
    "        n = torch.norm(s, dim=-1, keepdim=True)\n",
    "        return (1 - 1 / (torch.exp(n) + self.eps)) * (s / (n + self.eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_routing(x, iterations=3):\n",
    "    #x = x.unsqueeze(-1)\n",
    "    N = x.shape[1]  # num_caps\n",
    "    N1 = x.shape[2]  # in_caps\n",
    "    B = x.shape[0]\n",
    "    # feature_dim = x.shape[2]\n",
    "    #x:batch_size, num_caps, in_caps, out_channels\n",
    "    b = torch.zeros(B, N, N1,1).to(x.device)#batch_size, num_caps, in_caps\n",
    "    for _ in range(iterations):\n",
    "        #print('input x\\'s batch_size: {}, num_caps: {}, in_caps: {}, out_channels: {}'.format(x.shape[0], x.shape[1], x.shape[2], x.shape[3]))\n",
    "        c = F.softmax(b, dim=1)#Softmax along num_caps\n",
    "        #batch_size, num_caps,caps_dim\n",
    "        #print('softmax result\\'s batch_size: {}, num_caps: {}, in_caps: {}, softmax_result: {}'.format(c.shape[0], c.shape[1], c.shape[2], c.shape[3]))\n",
    "        a = c*x\n",
    "        #print('a\\'s batch_size: {}, num_caps: {}, in_caps: {}, out_channels: {}'.format(a.shape[0], a.shape[1], a.shape[2], a.shape[3]))\n",
    "        s = torch.sum(a, dim=2).squeeze(-1)#sum across in_caps\n",
    "        #print('s\\'s batch_size: {}, num_caps: {}, out_channels: {}'.format(s.shape[0], s.shape[1], s.shape[2]))\n",
    "        v = squash(s)# apply \"squashing\" non-linearity along out_channels\n",
    "        #print('v\\'s batch_size: {}, num_caps: {}, out_channels: {}'.format(v.shape[0], v.shape[1], v.shape[2]))\n",
    "        #print('x shape: {}'.format(x.shape))\n",
    "        y = torch.matmul(x,v.unsqueeze(-1))\n",
    "        #print('y shape: {}'.format(y.shape))\n",
    "        #print('b shape: {}'.format(b.shape))\n",
    "        b = b + y\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x's batch_size: 2, num_caps: 2, in_caps: 5, out_channels: 205\n",
      "softmax result's batch_size: 2, num_caps: 2, in_caps: 5, softmax_result: 1\n",
      "a's batch_size: 2, num_caps: 2, in_caps: 5, out_channels: 205\n",
      "s's batch_size: 2, num_caps: 2, out_channels: 205\n",
      "v's batch_size: 2, num_caps: 2, out_channels: 205\n",
      "x shape: torch.Size([2, 2, 5, 205])\n",
      "y shape: torch.Size([2, 2, 5, 1])\n",
      "b shape: torch.Size([2, 2, 5, 1])\n",
      "input x's batch_size: 2, num_caps: 2, in_caps: 5, out_channels: 205\n",
      "softmax result's batch_size: 2, num_caps: 2, in_caps: 5, softmax_result: 1\n",
      "a's batch_size: 2, num_caps: 2, in_caps: 5, out_channels: 205\n",
      "s's batch_size: 2, num_caps: 2, out_channels: 205\n",
      "v's batch_size: 2, num_caps: 2, out_channels: 205\n",
      "x shape: torch.Size([2, 2, 5, 205])\n",
      "y shape: torch.Size([2, 2, 5, 1])\n",
      "b shape: torch.Size([2, 2, 5, 1])\n",
      "input x's batch_size: 2, num_caps: 2, in_caps: 5, out_channels: 205\n",
      "softmax result's batch_size: 2, num_caps: 2, in_caps: 5, softmax_result: 1\n",
      "a's batch_size: 2, num_caps: 2, in_caps: 5, out_channels: 205\n",
      "s's batch_size: 2, num_caps: 2, out_channels: 205\n",
      "v's batch_size: 2, num_caps: 2, out_channels: 205\n",
      "x shape: torch.Size([2, 2, 5, 205])\n",
      "y shape: torch.Size([2, 2, 5, 1])\n",
      "b shape: torch.Size([2, 2, 5, 1])\n",
      "torch.Size([2, 2, 205])\n"
     ]
    }
   ],
   "source": [
    "#x:batch_size, num_caps, in_caps, out_channels\n",
    "input_tensor=torch.randn(2, 2, 5,205)\n",
    "print(dynamic_routing(input_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the input and output channels\n",
    "in_channels = 2\n",
    "out_channels = 1\n",
    "\n",
    "# Define the kernel size and dilation\n",
    "kernel_size = 2\n",
    "\n",
    "# Define the 1D dilated convolution layers\n",
    "conv1d_list = nn.ModuleList()\n",
    "for dilation in range(1, 6):\n",
    "    padding = \"same\"\n",
    "    conv1d_list.append(\n",
    "        nn.Conv1d(\n",
    "            in_channels, out_channels, kernel_size, dilation=dilation, padding=padding\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Define the input tensor\n",
    "input_tensor = torch.randn(1, in_channels, 21 * 5)\n",
    "\n",
    "# Apply the 1D dilated convolutions to the input tensor\n",
    "output_tensor_list = []\n",
    "for conv1d in conv1d_list:\n",
    "    print(conv1d(input_tensor).shape)\n",
    "    output_tensor_list.append(conv1d(input_tensor))\n",
    "\n",
    "# Concatenate the output tensors along the channel dimension\n",
    "output_tensor = torch.cat(output_tensor_list, dim=1)\n",
    "\n",
    "print(output_tensor.shape)\n",
    "print(dynamic_routing(output_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 1, 1])\n",
      "torch.Size([1, 1, 5, 105, 1])\n",
      "torch.Size([1, 1, 105])\n"
     ]
    }
   ],
   "source": [
    "c = F.softmax(torch.zeros(1, 1, 5, 1, 1), dim=1)\n",
    "# print(c)\n",
    "print(c.shape)\n",
    "x = torch.randn(1, 5, 21 * 5, 1)\n",
    "a = x.matmul(c)\n",
    "# print(a)\n",
    "print(a.shape)\n",
    "s = torch.sum(x.matmul(c), dim=2).squeeze(-1)\n",
    "# print(s)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 105])\n"
     ]
    }
   ],
   "source": [
    "class PrimaryCapsuleLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Create a primary capsule layer with the methodology described in 'Efficient-CapsNet: Capsule Network with Self-Attention Routing'.\n",
    "    Properties of each capsule s_n are exatracted using a 1D depthwise convolution.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    kernel_size[w]: int\n",
    "        depthwise conv kernel dimension\n",
    "    conv_num: int\n",
    "        number of primary capsules\n",
    "    feature_dimension: int\n",
    "        primary capsules dimension (number of properties)\n",
    "    conv_stride: int\n",
    "        depthwise conv strides\n",
    "    Methods\n",
    "    -------\n",
    "    forward(inputs)\n",
    "        compute the primary capsule layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        conv_in=2,\n",
    "        feature_dimension=272,#21 * 5,\n",
    "        kernel_size=2,\n",
    "        conv_num=5,\n",
    "        base_num=21,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_out = feature_dimension // (conv_num * base_num)\n",
    "        self.conv_num = conv_num\n",
    "        self.primary_capsule_layer = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(\n",
    "                    conv_in,\n",
    "                    self.conv_out,\n",
    "                    kernel_size,\n",
    "                    dilation=conv_stride,\n",
    "                    padding=\"same\",\n",
    "                )\n",
    "                for conv_stride in range(1, conv_num + 1)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print('input feature shape: {}'.format(x.shape))\n",
    "        capsules = [conv(x) for conv in self.primary_capsule_layer]\n",
    "        # capsules_reshaped = [\n",
    "        #    c.reshape(self.conv_num, self.feature_dimension) for c in capsules\n",
    "        # ]\n",
    "        output_tensor = torch.cat(capsules, dim=1)\n",
    "        return Squash()(output_tensor)\n",
    "\n",
    "\n",
    "def test_for_primary_capsule_layer():\n",
    "    input = torch.rand(1, 2, 105)\n",
    "    layer = PrimaryCapsuleLayer()\n",
    "    print(layer(input).shape)\n",
    "\n",
    "\n",
    "test_for_primary_capsule_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_capsules=1, in_caps=10, in_channels=272, out_channels=2#in_channels=105\n",
    "    ):\n",
    "        super(CapsLayer, self).__init__()\n",
    "        self.W = nn.Parameter(\n",
    "            torch.randn(1, num_capsules, in_caps, out_channels, in_channels)\n",
    "        )\n",
    "        # print('W shape: {}'.format(self.W.shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('CapsLayer input shape: {}'.format(x.shape))\n",
    "        x = x[:, None, ..., None]  # x.unsqueeze(1).unsqueeze(4)\n",
    "        # x = x.unsqueeze(-1)\n",
    "        #print('W shape: {}'.format(self.W.shape))\n",
    "        #print('CapsLayer input shape: {}'.format(x.shape))\n",
    "        # print('CapsLayer input expand shape: {}'.format(x[ :, :, None, :].shape))\n",
    "        # (batch_size, num_caps, num_route_nodes, out_channels, 1)\n",
    "        # print('x shape: {}'.format(x.shape))\n",
    "        u_hat = torch.matmul(self.W, x)  # (x @ self.W).squeeze(2)\n",
    "        # u=u_hat.squeeze(-1)\n",
    "        u_hat = u_hat.squeeze(-1)\n",
    "        #batch_size, num_caps, in_caps, out_channels\n",
    "        #print('u_hat\\'s batch_size: {}, num_caps: {}, in_caps: {}, out_channels: {}'.format(u_hat.shape[0], u_hat.shape[1], u_hat.shape[2], u_hat.shape[3]))\n",
    "        class_capsules = dynamic_routing(u_hat)\n",
    "        return class_capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1, 10, 10, 20, 1)\n",
    "b = torch.rand(1, 1, 10, 1, 1)\n",
    "c = a.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CapsLayer input shape: torch.Size([2, 5, 105])\n",
      "W shape: torch.Size([1, 1, 5, 2, 105])\n",
      "CapsLayer input shape: torch.Size([2, 1, 5, 105, 1])\n",
      "u_hat's batch_size: 2, num_caps: 1, in_caps: 5, out_channels: 2\n",
      "input x's batch_size: 2, num_caps: 1, in_caps: 5, out_channels: 2\n",
      "softmax result's batch_size: 2, num_caps: 1, in_caps: 5, softmax_result: 1\n",
      "a's batch_size: 2, num_caps: 1, in_caps: 5, out_channels: 2\n",
      "s's batch_size: 2, num_caps: 1, out_channels: 2\n",
      "v's batch_size: 2, num_caps: 1, out_channels: 2\n",
      "x shape: torch.Size([2, 1, 5, 2])\n",
      "y shape: torch.Size([2, 1, 5, 1])\n",
      "b shape: torch.Size([2, 1, 5, 1])\n",
      "input x's batch_size: 2, num_caps: 1, in_caps: 5, out_channels: 2\n",
      "softmax result's batch_size: 2, num_caps: 1, in_caps: 5, softmax_result: 1\n",
      "a's batch_size: 2, num_caps: 1, in_caps: 5, out_channels: 2\n",
      "s's batch_size: 2, num_caps: 1, out_channels: 2\n",
      "v's batch_size: 2, num_caps: 1, out_channels: 2\n",
      "x shape: torch.Size([2, 1, 5, 2])\n",
      "y shape: torch.Size([2, 1, 5, 1])\n",
      "b shape: torch.Size([2, 1, 5, 1])\n",
      "input x's batch_size: 2, num_caps: 1, in_caps: 5, out_channels: 2\n",
      "softmax result's batch_size: 2, num_caps: 1, in_caps: 5, softmax_result: 1\n",
      "a's batch_size: 2, num_caps: 1, in_caps: 5, out_channels: 2\n",
      "s's batch_size: 2, num_caps: 1, out_channels: 2\n",
      "v's batch_size: 2, num_caps: 1, out_channels: 2\n",
      "x shape: torch.Size([2, 1, 5, 2])\n",
      "y shape: torch.Size([2, 1, 5, 1])\n",
      "b shape: torch.Size([2, 1, 5, 1])\n",
      "torch.Size([2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(2, 5, 105)\n",
    "layer = CapsLayer()\n",
    "print(layer(input).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(512,1,272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self,vocab_size=16,embedding_size=16):\n",
    "        super(CapsNet, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.primary_layer = PrimaryCapsuleLayer()\n",
    "        self.caps_layer = CapsLayer()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "    def forward(self, seq,sig):\n",
    "        seq_emb = self.embed(seq.long())\n",
    "        seq_emb = seq_emb.reshape(seq_emb.shape[0], 1, -1)\n",
    "        sig = sig.reshape(sig.shape[0], 1, -1)\n",
    "        print('seq_emb shape: {}'.format(seq_emb.shape))\n",
    "        print('sig shape: {}'.format(sig.shape))\n",
    "        x = torch.cat((seq_emb,sig), dim=1).to(torch.float32)\n",
    "        #seq = self.primary_layer(seq)\n",
    "        #seq = self.caps_layer(seq)\n",
    "        #sig = self.primary_layer(sig)\n",
    "        #sig = self.caps_layer(sig)\n",
    "        x = self.primary_layer(x)\n",
    "        x = self.caps_layer(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.norm(x,dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_for_caps_net():\n",
    "    input1 = torch.rand(1, 1, 105)\n",
    "    input2 = torch.rand(1, 1, 105)\n",
    "    \n",
    "    model = CapsNet()\n",
    "    #print(model(input1,input2).shape)\n",
    "\n",
    "\n",
    "test_for_caps_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsuleLoss, self).__init__()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, classes, labels):\n",
    "        #classes = classes.reshape(classes.shape[0], 2)\n",
    "        #labels = labels.reshape(labels.shape[0], 1)\n",
    "        #print('classes shape: {}'.format(classes.shape))\n",
    "        #print('labels shape: {}'.format(labels.shape))\n",
    "        #left = F.relu(0.9 - classes[0], inplace=True) ** 2\n",
    "        #print('left shape: {}'.format(left.shape))\n",
    "        #right = F.relu(classes[1] - 0.1, inplace=True) ** 2\n",
    "        #print('right shape: {}'.format(right.shape))\n",
    "\n",
    "        #margin_loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "        #margin_loss = margin_loss.sum()\n",
    "        return self.loss(classes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import linecache\n",
    "\n",
    "base2code_dna = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3, \"N\": 4}\n",
    "code2base_dna = {0: \"A\", 1: \"C\", 2: \"G\", 3: \"T\", 4: \"N\"}\n",
    "\n",
    "\n",
    "def clear_linecache():\n",
    "    # linecache should be treated carefully\n",
    "    linecache.clearcache()\n",
    "\n",
    "\n",
    "def parse_a_line(line):\n",
    "    words = line.strip().split(\"\\t\")\n",
    "\n",
    "    seq = np.array(\n",
    "        [[base2code_dna[y] for y in x.split(\",\")] for x in words[1].split(\";\")]\n",
    "    )\n",
    "    signal = np.array(\n",
    "        [[np.float16(y) for y in x.split(\",\")] for x in words[2].split(\";\")]\n",
    "    )\n",
    "    label = np.random.randint(0, 2)\n",
    "    #if rlabel==1:\n",
    "    #    label=[0,1]\n",
    "    #else:\n",
    "    #    label=[1,0]\n",
    "\n",
    "    return seq, signal, label\n",
    "\n",
    "\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, filename, transform=None):\n",
    "        # print(\">>>using linecache to access '{}'<<<\\n\"\n",
    "        #       \">>>after done using the file, \"\n",
    "        #       \"remember to use linecache.clearcache() to clear cache for safety<<<\".format(filename))\n",
    "        self._filename = os.path.abspath(filename)\n",
    "        self._total_data = 0\n",
    "        self._transform = transform\n",
    "        with open(filename, \"r\") as f:\n",
    "            self._total_data = len(f.readlines())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = linecache.getline(self._filename, idx + 1)\n",
    "        if line == \"\":\n",
    "            return None\n",
    "        else:\n",
    "            output = parse_a_line(line)\n",
    "            if self._transform is not None:\n",
    "                output = self._transform(output)\n",
    "            return output\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._total_data\n",
    "\n",
    "def parse_a_line2(line):\n",
    "    words = line.strip().split(\"\\t\")\n",
    "\n",
    "    sampleinfo = \"\\t\".join(words[0:6])\n",
    "\n",
    "    kmer = np.array([base2code_dna[x] for x in words[6]])\n",
    "    base_means = np.array([float(x) for x in words[7].split(\",\")])\n",
    "    base_stds = np.array([float(x) for x in words[8].split(\",\")])\n",
    "    base_signal_lens = np.array([int(x) for x in words[9].split(\",\")])\n",
    "    k_signals = np.array([[float(y) for y in x.split(\",\")] for x in words[10].split(\";\")])\n",
    "    label = int(words[11])\n",
    "\n",
    "    return kmer, k_signals, label   \n",
    "class SignalFeaData2(Dataset):\n",
    "    def __init__(self, filename, transform=None):\n",
    "        # print(\">>>using linecache to access '{}'<<<\\n\"\n",
    "        #       \">>>after done using the file, \"\n",
    "        #       \"remember to use linecache.clearcache() to clear cache for safety<<<\".format(filename))\n",
    "        self._filename = os.path.abspath(filename)\n",
    "        self._total_data = 0\n",
    "        self._transform = transform\n",
    "        with open(filename, \"r\") as f:\n",
    "            self._total_data = len(f.readlines())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = linecache.getline(self._filename, idx + 1)\n",
    "        if line == \"\":\n",
    "            return None\n",
    "        else:\n",
    "            output = parse_a_line2(line)\n",
    "            if self._transform is not None:\n",
    "                output = self._transform(output)\n",
    "            return output\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._total_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch.utils.data import sampler\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total_start = time.time()\n",
    "    args = parse_args()\n",
    "    train_dataset = SignalFeaData2(args.train_file)\n",
    "\n",
    "    split_num = int(len(train_dataset) * 0.8)\n",
    "    index_list = list(range(len(train_dataset)))\n",
    "    train_idx, val_idx = index_list[:split_num], index_list[split_num:]\n",
    " \n",
    "    train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(val_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset, batch_size=args.batch_size, sampler=train_sampler\n",
    "    )\n",
    "    total_step = len(train_loader)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset, batch_size=args.batch_size, sampler=val_sampler\n",
    "    )\n",
    "    model = CapsNet()\n",
    "    criterion = CapsuleLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "    curr_best_accuracy = 0\n",
    "    model_dir = args.model_dir\n",
    "    if model_dir != \"/\":\n",
    "        model_dir = os.path.abspath(model_dir).rstrip(\"/\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        else:\n",
    "            model_regex = re.compile(\n",
    "                r\"\" + \"\\.b\\d+_s\\d+_epoch\\d+\\.ckpt*\"\n",
    "            )\n",
    "            for mfile in os.listdir(model_dir):\n",
    "                if model_regex.match(mfile):\n",
    "                    os.remove(model_dir + \"/\" + mfile)\n",
    "        model_dir += \"/\"\n",
    "    model.train()\n",
    "    for epoch in range(args.max_epoch_num):\n",
    "        curr_best_accuracy_epoch = 0\n",
    "        no_best_model = True\n",
    "        tlosses = []\n",
    "        start = time.time()\n",
    "        for i, sfeatures in tqdm(enumerate(train_loader)):\n",
    "            (seq, signal, labels) = sfeatures\n",
    "            outputs = model(seq, signal)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #print(loss)\n",
    "            print(loss.detach().item())\n",
    "            tlosses.append(loss.detach().item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            if (i + 1) % args.step_interval == 0 or i == total_step - 1:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    vlosses, vlabels_total, vpredicted_total = [], [], []\n",
    "                    for vi, vsfeatures in tqdm(enumerate(valid_loader)):\n",
    "                        (\n",
    "                            vseq,\n",
    "                            vsignal,\n",
    "                            vlabels,\n",
    "                        ) = vsfeatures\n",
    "                        voutputs = model(vseq, vsignal)\n",
    "                        vloss = criterion(voutputs, vlabels)\n",
    "\n",
    "                        _, vpredicted = torch.max(voutputs.data, 1)\n",
    "                        #print(vpredicted)\n",
    "                        vlosses.append(vloss.item())\n",
    "                        vlabels_total += vlabels.tolist()\n",
    "                        vpredicted_total += vpredicted.tolist()\n",
    "                        v_accuracy = metrics.accuracy_score(\n",
    "                            vlabels_total, vpredicted_total\n",
    "                        )\n",
    "                        v_precision = metrics.precision_score(\n",
    "                            vlabels_total, vpredicted_total\n",
    "                        )\n",
    "                        v_recall = metrics.recall_score(vlabels_total, vpredicted_total)\n",
    "                        if v_accuracy > curr_best_accuracy_epoch:\n",
    "                            curr_best_accuracy_epoch = v_accuracy\n",
    "                            if curr_best_accuracy_epoch > curr_best_accuracy - 0.0002:\n",
    "                                torch.save(\n",
    "                                    model.state_dict(),\n",
    "                                    model_dir\n",
    "                                    + \".epoch{}.ckpt\".format(\n",
    "                                        epoch\n",
    "                                    ),\n",
    "                                )\n",
    "                                if curr_best_accuracy_epoch > curr_best_accuracy:\n",
    "                                    curr_best_accuracy = curr_best_accuracy_epoch\n",
    "                                    no_best_model = False\n",
    "                        time_cost = time.time() - start\n",
    "                        print(\n",
    "                            \"Epoch [{}/{}], Step [{}/{}], TrainLoss: {:.4f}; \"\n",
    "                            \"ValidLoss: {:.4f}, \"\n",
    "                            \"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, \"\n",
    "                            \"curr_epoch_best_accuracy: {:.4f}; Time: {:.2f}s\".format(\n",
    "                                epoch + 1,\n",
    "                                args.max_epoch_num,\n",
    "                                i + 1,\n",
    "                                total_step,\n",
    "                                np.mean(tlosses),\n",
    "                                np.mean(vlosses),\n",
    "                                v_accuracy,\n",
    "                                v_precision,\n",
    "                                v_recall,\n",
    "                                curr_best_accuracy_epoch,\n",
    "                                time_cost,\n",
    "                            )\n",
    "                        )\n",
    "                        tlosses = []\n",
    "                        start = time.time()\n",
    "                        sys.stdout.flush()\n",
    "                    model.train()\n",
    "            scheduler.step()\n",
    "            if no_best_model and epoch >= args.min_epoch_num - 1:\n",
    "                print(\"early stop!\")\n",
    "                break\n",
    "        endtime = time.time()\n",
    "        clear_linecache()\n",
    "        print(\n",
    "            \"[main] train costs {} seconds, \"\n",
    "            \"best accuracy: {}\".format(endtime - total_start, curr_best_accuracy)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
